{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet8 \n",
    "## Foundation Baseline\n",
    "\n",
    "1. foundation\n",
    "\n",
    "\n",
    "## overview\n",
    "- `data_prep` までは公開ベースラインと同じ\n",
    "- 学習部分のみの改善を試みる\n",
    "- pytorch lightning + wandb + SMP or TimmUNet の導入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "python-box\n",
    "tqdm\n",
    "timm\n",
    "ttach\n",
    "adabelief-pytorch\n",
    "albumentations\n",
    "segmentation-models-pytorch\n",
    "wandb\n",
    "tensorboard\n",
    "tensorboardX\n",
    "pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torch==1.8.0+cu111) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torch==1.8.0+cu111) (1.23.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torchvision==0.9.0+cu111) (9.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.0\n",
      "    Uninstalling torchvision-0.13.0:\n",
      "      Successfully uninstalled torchvision-0.13.0\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -r ../docker/requirements.txt\n",
    "!pip install -q -r requirements.txt\n",
    "!conda install -y gdal\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyuchimu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/syu/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "from pprint import pprint\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "import glob\n",
    "import json\n",
    "import csv\n",
    "# import dataclasses\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from box import Box\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tifffile\n",
    "from osgeo import gdal\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from timm import create_model\n",
    "from adabelief_pytorch import AdaBelief\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import wandb\n",
    "wandb.login(key='****')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "pd.options.display.max_colwidth = 250\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# インライン表示\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATH_FOLD_CSV': '../../data/folds/',\n",
      " 'augmentation': '',\n",
      " 'debug': False,\n",
      " 'debug_sample': 32,\n",
      " 'epoch': 100,\n",
      " 'eps': 1e-12,\n",
      " 'f': 'flood',\n",
      " 'features': BoxList(['preimg', 'building', 'road', 'roadspeed', 'flood']),\n",
      " 'fold': -1,\n",
      " 'folds': 5,\n",
      " 'group': '3090_V1_IMG512_effb6_decoder512_flip-trans',\n",
      " 'model': {'act': None,\n",
      "           'architecture': 'smp',\n",
      "           'decoder_channels': BoxList([512, 256, 128, 64, 32]),\n",
      "           'encoder_name': 'efficientnet-b6',\n",
      "           'in_channels': 3,\n",
      "           'loss': 'MultiBCEDiceLoss(raito=0.5)',\n",
      "           'loss_mode': 'multilabel',\n",
      "           'out_channels': 9,\n",
      "           'threshold': 0.2},\n",
      " 'notebook': 'baseline_foundation.ipynb',\n",
      " 'optimizer': Box({'name': 'optim.AdamW', 'params': {'lr': 0.001}}),\n",
      " 'outdir': '../../train/output/foundation/',\n",
      " 'preprocess': Box({'input_size': 512}),\n",
      " 'project': 'SpaceNet8_foundation',\n",
      " 'runname': '3090',\n",
      " 'scheduler': {'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
      "               'params': Box({'T_0': 20, 'eta_min': 1e-05})},\n",
      " 'seed': 417,\n",
      " 'train_loader': {'batch_size': 8,\n",
      "                  'drop_last': True,\n",
      "                  'num_workers': 8,\n",
      "                  'pin_memory': False,\n",
      "                  'shuffle': True},\n",
      " 'trainer': {'accumulate_grad_batches': 1,\n",
      "             'check_val_every_n_epoch': 2,\n",
      "             'fast_dev_run': False,\n",
      "             'gpus': 1,\n",
      "             'gradient_clip_algorithm': 'value',\n",
      "             'gradient_clip_val': 10.0,\n",
      "             'num_sanity_val_steps': 0,\n",
      "             'precision': 16,\n",
      "             'progress_bar_refresh_rate': 1,\n",
      "             'resume_from_checkpoint': None,\n",
      "             'stochastic_weight_avg': False,\n",
      "             'val_check_interval': 1.0},\n",
      " 'val_loader': {'batch_size': 8,\n",
      "                'drop_last': False,\n",
      "                'num_workers': 8,\n",
      "                'pin_memory': False,\n",
      "                'shuffle': False}}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Set, Dict, Any\n",
    "\n",
    "class CFG(object):\n",
    "    # basic\n",
    "    debug: bool = False\n",
    "    debug_sample: int = 32\n",
    "    folds: int  = 5\n",
    "    seed: int   = 417\n",
    "    eps: float  = 1e-12\n",
    "    outdir: str = '../../train/output/foundation/'\n",
    "    \n",
    "    # data\n",
    "    PATH_FOLD_CSV: str  =  f'../../data/folds/'\n",
    "    \n",
    "    # train\n",
    "    epoch: int  = 00\n",
    "    trainer: Dict[str, Any]   = {\n",
    "        'gpus': 1,\n",
    "        'accumulate_grad_batches': 1,\n",
    "        'progress_bar_refresh_rate': 1,\n",
    "        'stochastic_weight_avg': False,\n",
    "        'fast_dev_run': False,\n",
    "        'num_sanity_val_steps': 0,\n",
    "        'resume_from_checkpoint': None,\n",
    "        'check_val_every_n_epoch': 2,\n",
    "        'val_check_interval': 1.0,\n",
    "        'precision' : 16,\n",
    "        'gradient_clip_val': 10., \n",
    "        'gradient_clip_algorithm': \"value\"\n",
    "    }\n",
    "    optimizer: Dict[str, Any] = {\n",
    "        'name': 'optim.AdamW',\n",
    "        'params': {\n",
    "            'lr': 1e-3,\n",
    "            },\n",
    "    }\n",
    "    scheduler: Dict[str, Any] = {\n",
    "        'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "        'params':{\n",
    "            'T_0': 20,\n",
    "            'eta_min': 1e-5,\n",
    "            }\n",
    "    }\n",
    "    model: Dict[str, Any] = {\n",
    "        \"architecture\": 'smp', # timmu, smp\n",
    "        \"threshold\": 0.2,\n",
    "        \n",
    "        'loss': 'MultiBCEDiceLoss(raito=0.5)',\n",
    "        # smp loss mode: https://smp.readthedocs.io/en/latest/_modules/segmentation_models_pytorch/losses/dice.html\n",
    "        'loss_mode': 'multilabel', # 'binary', 'multiclass' ,'multilabel'\n",
    "        \n",
    "        'in_channels': 0,\n",
    "        'out_channels': 0,\n",
    "        \n",
    "        # unet++ :https://smp.readthedocs.io/en/latest/_modules/segmentation_models_pytorch/decoders/unetplusplus/model.html\n",
    "        'decoder_channels': [int(512 / 2**i) for i in range(5)],\n",
    "        'encoder_name': 'efficientnet-b6',\n",
    "        'act': None,\n",
    "        # 'dropout_rato': 0.1,\n",
    "    }\n",
    "    train_loader: Dict[str, Any] = {\n",
    "        'batch_size': 8,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 8,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': True,\n",
    "    }\n",
    "    val_loader :Dict[str, Any]= {\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 8,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': False\n",
    "    }\n",
    "    \n",
    "    # preprocess\n",
    "    features :List[str] = [\"preimg\", \"building\",\"road\",\"roadspeed\",\"flood\"]\n",
    "    # [\"preimg\",\"postimg\",\"building\",\"road\",\"roadspeed\",\"flood\"]\n",
    "    \n",
    "    preprocess: Dict = {\n",
    "        \"input_size\": 512,\n",
    "    }\n",
    "    \n",
    "    # logging\n",
    "    project: str = \"SpaceNet8_foundation\"\n",
    "    runname: str = \"3090\"\n",
    "    group: str   = f'3090_V1_IMG{preprocess[\"input_size\"]}_effb6_decoder512_flip-trans'\n",
    "    notebook: str = 'baseline_foundation.ipynb'\n",
    "    \n",
    "    # post info\n",
    "    augmentation: str =  ''\n",
    "    fold: int = -1\n",
    "    \n",
    "    \n",
    "    # channels\n",
    "    for f in features:\n",
    "        if f == 'preimg':\n",
    "            model['in_channels'] += 3\n",
    "        elif f == 'postimg':\n",
    "            model['in_channels'] += 3\n",
    "\n",
    "        if f == 'building':\n",
    "            model['out_channels'] += 1\n",
    "        # elif f == 'road':\n",
    "        #     model['out_channels']  += 1\n",
    "        elif f == 'roadspeed':\n",
    "            model['out_channels']  += 8\n",
    "        # elif f == 'flood':\n",
    "        #     model['out_channels']  += 4\n",
    "        \n",
    "\n",
    "    if debug:\n",
    "        epoch = 2\n",
    "        group = 'DEBUG'\n",
    "\n",
    "\n",
    "# box\n",
    "cfg = Box({k:v for k, v in dict(vars(CFG)).items() if '__' not in k})\n",
    "    \n",
    "# 乱数のシードを設定\n",
    "seed_everything(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "random.seed(cfg.seed)\n",
    "    \n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'train':Compose([Transpose(always_apply=False,p=0.25),Flip(always_apply=False,p=0.5),Resize(always_apply=False,p=1,height=512,width=512,interpolation=1),ToTensorV2(always_apply=True,p=1.0,transpose_mask=False),],p=1.0,bbox_params=None,keypoint_params=None,additional_targets={}),'val':Compose([Resize(always_apply=False,p=1,height=512,width=512,interpolation=1),ToTensorV2(always_apply=True,p=1.0,transpose_mask=False),],p=1.0,bbox_params=None,keypoint_params=None,additional_targets={})}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# augmentation\n",
    "tf_dict = {\n",
    "    \n",
    "    'train': A.Compose(\n",
    "        [\n",
    "\n",
    "            # A.CoarseDropout(max_holes=4, max_height=4, max_width=4, \n",
    "            #                     min_holes=None, min_height=None, min_width=None, \n",
    "            #                     fill_value=0.15, mask_fill_value=0.0, always_apply=False, p=0.25),\n",
    "            # A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1,\n",
    "            #                     border_mode=4, value=None, mask_value=None, always_apply=False,\n",
    "            #                     approximate=False, same_dxdy=False, p=0.25),\n",
    "            # A.GridDistortion(num_steps=5, distort_limit=0.4, interpolation=1, \n",
    "            #                     border_mode=4, value=None, mask_value=None, always_apply=False, p=0.25),\n",
    "            # A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, interpolation=1, \n",
    "            #                     border_mode=4, value=0.01, mask_value=0.0, shift_limit_x=None, shift_limit_y=None, \n",
    "            #                     p=0.5),\n",
    "            # A.OneOf([\n",
    "            #     # A.GaussNoise(var_limit=(1e-3, 8e-1), mean=0.15, p=0.5),\n",
    "            #     A.Blur(blur_limit=9, p=0.25),\n",
    "            #     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, brightness_by_max=True, p=0.5),\n",
    "            # ], p=0.9),\n",
    "            A.Transpose(p=0.25),\n",
    "            A.Flip(p=0.5),\n",
    "            # A.HueSaturationValue (hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.5),\n",
    "            # A.Rotate(limit=30, p=0.5),\n",
    "            A.Resize(cfg.preprocess.input_size, cfg.preprocess.input_size),\n",
    "    #         A.Normalize(mean=(0.485), std=(0.229)),\n",
    "            ToTensorV2(),\n",
    "            ]\n",
    "        ),\n",
    "    'val': A.Compose(\n",
    "        [\n",
    "            A.Resize(cfg.preprocess.input_size, cfg.preprocess.input_size),\n",
    "            # A.Normalize(mean=(0.485), std=(0.229)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "cfg.augmentation = str(tf_dict).replace('\\n', '').replace(' ', '')\n",
    "cfg.augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceNnet8Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 fold: int,\n",
    "                 phase: str,\n",
    "                 ):\n",
    "        \"\"\" pytorch dataset for spacenet-8 data. loads images from a csv that contains filepaths to the images\n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "        fold: (int) \n",
    "            preimg column contains filepaths to the pre-event image tiles (.tif)\n",
    "            postimg column contains filepaths to the post-event image tiles (.tif)\n",
    "            building column contains the filepaths to the binary building labels (.tif)\n",
    "            road column contains the filepaths to the binary road labels (.tif)\n",
    "            roadspeed column contains the filepaths to the road speed labels (.tif)\n",
    "            flood column contains the filepaths to the flood labels (.tif)\n",
    "        data_to_load (list): a list that defines which of the images and labels to load from the .csv. \n",
    "        \n",
    "        \"\"\"\n",
    "        self.all_data_types = [\"preimg\", \"postimg\", \"building\", \"road\", \"roadspeed\", \"flood\"]\n",
    "        \n",
    "        self.data_to_load = cfg.features\n",
    "        self.phase = phase\n",
    "        csv_filename = os.path.join(cfg.PATH_FOLD_CSV, f'fold{fold}_seed{cfg.seed}_{self.phase}.csv')\n",
    "        self.transform = tf_dict[self.phase]\n",
    "        \n",
    "        self.files = []\n",
    "\n",
    "        dict_template = {}\n",
    "        for i in self.all_data_types:\n",
    "            dict_template[i] = None\n",
    "        \n",
    "        with open(csv_filename, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for k, row in enumerate(reader):\n",
    "                in_data = copy.copy(dict_template)\n",
    "                for j in self.data_to_load:\n",
    "                    in_data[j]=row[j]\n",
    "                self.files.append(in_data)\n",
    "                \n",
    "                if cfg.debug and k > cfg.debug_sample:\n",
    "                    break\n",
    "        \n",
    "        print(\"loaded\", len(self.files), \"image filepaths\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_dict = self.files[index]\n",
    "\n",
    "        imgs, masks = [], []\n",
    "        \n",
    "        # gather\n",
    "        for i in self.all_data_types:\n",
    "            filepath = data_dict[i]\n",
    "            if filepath is not None:\n",
    "                # need to resample postimg to same spatial resolution/extent as preimg and labels.\n",
    "                if i == \"postimg\":\n",
    "                    ds = self.get_warped_ds(data_dict[\"postimg\"])\n",
    "                else:\n",
    "                    ds = gdal.Open(filepath)\n",
    "                image = ds.ReadAsArray()\n",
    "                ds = None\n",
    "            \n",
    "                if i in ['preimg' ,'postimg']:\n",
    "                    imgs.append(image.transpose(1, 2, 0))\n",
    "                else:\n",
    "                    # 1 channel\n",
    "                    if len(image.shape) <= 2:\n",
    "                        masks.append(image[:,:, np.newaxis])\n",
    "                    else:\n",
    "                        masks.append(image.transpose(1, 2, 0))\n",
    "                        \n",
    "                \n",
    "        \n",
    "        \n",
    "        # align channel last\n",
    "        imgs = np.concatenate(imgs, axis=2)\n",
    "        masks = np.concatenate(masks, axis=2)\n",
    "        \n",
    "        # augmentation\n",
    "        transformed = self.transform(image=imgs, mask=masks)\n",
    "        \n",
    "        imgs = transformed[\"image\"]\n",
    "        masks = transformed[\"mask\"].permute(2, 0, 1) # torch channel fast\n",
    "        \n",
    "        return imgs, masks\n",
    "\n",
    "    def get_image_filename(self, index: int) -> str:\n",
    "        \"\"\" return pre-event image absolute filepath at index \"\"\"\n",
    "        data_dict = self.files[index]\n",
    "        return data_dict[\"preimg\"]\n",
    "\n",
    "    def get_warped_ds(self, post_image_filename: str) -> gdal.Dataset:\n",
    "        \"\"\" gdal warps (resamples) the post-event image to the same spatial resolution as the pre-event image and masks \n",
    "        \n",
    "        SN8 labels are created from referencing pre-event image. Spatial resolution of the post-event image does not match the spatial resolution of the pre-event imagery and therefore the labels.\n",
    "        In order to align the post-event image with the pre-event image and mask labels, we must resample the post-event image to the resolution of the pre-event image. Also need to make sure\n",
    "        the post-event image covers the exact same spatial extent as the pre-event image. this is taken care of in the the tiling\"\"\"\n",
    "        ds = gdal.Warp(\"\", post_image_filename,\n",
    "                       format='MEM', width=1300, height=1300,\n",
    "                       resampleAlg=gdal.GRIORA_Bilinear,\n",
    "                       outputType=gdal.GDT_Byte)\n",
    "        return ds\n",
    "    \n",
    "class SpaceNnet8Module(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fold,\n",
    "        cfg,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fold = fold\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = SpaceNnet8Dataset(self.fold, phase='train')\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = SpaceNnet8Dataset(self.fold, phase='val')\n",
    "        return DataLoader(dataset, **self._cfg.val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(smp.utils.base.Loss):\n",
    "    \"\"\"DiceLoss which supports ignore mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=cfg.eps, beta=0.5, ignore_mask_channel=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.beta = beta\n",
    "        self.ignore_mask_channel = ignore_mask_channel\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        # y_pr, y_gt = _apply_ignore_mask(y_pr, y_gt, self.ignore_mask_channel)\n",
    "\n",
    "        return 1 - smp.utils.functional.f_score(\n",
    "            y_pr,\n",
    "            y_gt,\n",
    "            beta=self.beta,\n",
    "            eps=self.eps,\n",
    "            threshold=None,\n",
    "            ignore_channels=None,\n",
    "        )\n",
    "\n",
    "class BCEDiceLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.dice_criterion = DiceLoss()\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss = self.raito * self.bce_criterion(y_pr, y_gt) + (1 - self.raito) * self.dice_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        return loss\n",
    "    \n",
    "class MultiBCEDiceLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(MultiBCEDiceLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.dice_criterion = smp.losses.DiceLoss(mode=cfg.model.loss_mode)\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss_bce = self.raito * self.bce_criterion(y_pr, y_gt)\n",
    "\n",
    "        if cfg.model.loss_mode == 'multiclass':\n",
    "            y_gt = y_gt.long()\n",
    "            y_gt = torch.argmax(y_gt, dim=1)\n",
    "        loss_dice = (1 - self.raito) * self.dice_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        \n",
    "        loss = loss_bce + loss_dice\n",
    "        return loss\n",
    "\n",
    "class MultiBCETverskyLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(MultiBCETverskyLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.tvrsky_criterion = smp.losses.TverskyLoss(mode=cfg.model.loss_mode, log_loss=False)\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss_bce = self.raito * self.bce_criterion(y_pr, y_gt)\n",
    "\n",
    "        if cfg.model.loss_mode == 'multiclass':\n",
    "            y_gt = y_gt.long()\n",
    "            y_gt = torch.argmax(y_gt, dim=1)\n",
    "        loss_dice = (1 - self.raito) * self.tvrsky_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        \n",
    "        loss = loss_bce + loss_dice\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam\n",
    "\n",
    "\n",
    "class SpaceNet8Model(LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(cfg.model.loss)\n",
    "        \n",
    "    def __build_model(self):\n",
    "        self.backbone = smp.UnetPlusPlus(encoder_name=cfg.model.encoder_name,\n",
    "                                              encoder_weights=\"imagenet\",\n",
    "                                      decoder_attention_type='scse',\n",
    "                                      in_channels=cfg.model.in_channels, activation=cfg.model.act,\n",
    "                                      decoder_channels=cfg.model.decoder_channels,\n",
    "                                      classes=cfg.model.out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        \n",
    "        return feat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.__share_step(batch, 'train')\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.__share_step(batch, 'val')\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, labels = batch\n",
    "        labels = labels.float()\n",
    "        images = images.float()\n",
    "\n",
    "        feat = self.forward(images)\n",
    "        build = feat[:, 0, :, :].unsqueeze(dim=1)\n",
    "        speed = feat[:, 1:9, :, :]\n",
    "\n",
    "        # loss\n",
    "        loss_build = self._criterion(build, labels[:, 0,...].unsqueeze(dim=1))\n",
    "        # loss_road = self._criterion(road, labels[:, 1,...].unsqueeze(dim=1))\n",
    "        loss_speed = self._criterion(speed, labels[:, 1:9,...])\n",
    "        # loss_flood = self._criterion(flood, labels[:, 10:14,...])\n",
    "        # sum\n",
    "        loss = loss_build + loss_speed\n",
    "        \n",
    "        logits = torch.sigmoid(torch.cat([build, speed], dim=1))\n",
    "        preds = (logits > cfg.model.threshold).float()\n",
    "        return_dict = {'loss': loss , \n",
    "                       'loss_build': loss_build, 'loss_speed': loss_speed}\n",
    "        \n",
    "        # metrics\n",
    "        for c in range(cfg.model.out_channels):\n",
    "            preds_c, labels_c = preds[:, c, :, :], labels[:, c, :, :]\n",
    "            tp = (preds_c * labels_c).sum().to(torch.float32)\n",
    "            tn = ((1. - preds_c) * (1. - labels_c)).sum().to(torch.float32)\n",
    "            fp = (preds_c * (1. - labels_c)).sum().to(torch.float32)\n",
    "            fn = ((1. - preds_c) * labels_c).sum().to(torch.float32)\n",
    "            return_dict[f'TP_{c}'] = tp.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'TN_{c}'] = tn.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'FP_{c}'] = fp.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'FN_{c}'] = fn.unsqueeze(dim=0).detach().cpu()\n",
    "            \n",
    "            precision = tp / (tp + fp + cfg.eps)\n",
    "            recall = tp / (tp + fn + cfg.eps)\n",
    "            f1 = 2 * (precision*recall) / (precision + recall + cfg.eps)\n",
    "            iou = tp / (tp + fp + fn + cfg.eps)\n",
    "            \n",
    "            return_dict[f'Precision_{c}'] = precision.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'Recall_{c}'] = recall.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'F1_{c}'] = f1.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'IoU_{c}'] = iou.unsqueeze(dim=0).detach().cpu()\n",
    "            \n",
    "            # logging \n",
    "            self.log(f'{mode}/iter_TP_{c}', tp)\n",
    "            self.log(f'{mode}/iter_TN_{c}', tn)\n",
    "            self.log(f'{mode}/iter_FP_{c}', fp)\n",
    "            self.log(f'{mode}/iter_FN_{c}', fn)\n",
    "            \n",
    "            self.log(f'{mode}/iter_Precision_{c}', precision)\n",
    "            self.log(f'{mode}/iter_Recall_{c}', recall)\n",
    "            \n",
    "            self.log(f'{mode}/iter_F1_{c}', f1)\n",
    "            self.log(f'{mode}/iter_IoU_{c}', iou) \n",
    "            \n",
    "        self.log(f'{mode}/iter_loss', loss)\n",
    "        for target in ['build', 'speed',]:\n",
    "            self.log(f'{mode}/iter_loss_{target}', eval(f'loss_{target}'))\n",
    "\n",
    "        return return_dict\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.__share_epoch_end(outputs, 'train')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.__share_epoch_end(outputs, 'val')    \n",
    "        \n",
    "    def __share_epoch_end(self, outputs, mode):\n",
    "        \n",
    "        # loss\n",
    "        losses = []\n",
    "        for target in ['build', 'speed',]:\n",
    "            exec(f'losses_{target} = []')\n",
    "            \n",
    "        for out in outputs:\n",
    "            losses.append(out['loss'].cpu().detach().numpy())\n",
    "        losses = np.mean(losses)\n",
    "        self.log(f'{mode}/epoch_loss', losses)\n",
    "        \n",
    "        for target in ['build', 'speed',]:\n",
    "            for out in outputs:\n",
    "                exec(f\"losses_{target}.append(out[f'loss_{target}'].cpu().detach().numpy())\")\n",
    "            exec(f'losses_{target} = np.mean(losses_{target})')\n",
    "            exec(f'self.log(f\"{mode}/epoch_loss_{target}\", losses_{target})')\n",
    "        \n",
    "        mean_iou = 0\n",
    "        mean_f1 = 0\n",
    "    \n",
    "        # metrics\n",
    "        for c in range(cfg.model.out_channels):\n",
    "            tps, tns, fps, fns, precisions, recalls, f1s, IoUs = \\\n",
    "                [], [], [], [], [], [], [], []\n",
    "            for out in outputs:\n",
    "                # assert False, (out[f'TP_{c}'], out[f'TP_{c}'].shape)\n",
    "                for (tp, tn, fp, fn, precision, recall, f1, iou) in zip(out[f'TP_{c}'], \n",
    "                                         out[f'TN_{c}'],\n",
    "                                         out[f'FP_{c}'],\n",
    "                                         out[f'FN_{c}'],\n",
    "                                         out[f'Precision_{c}'],\n",
    "                                         out[f'Recall_{c}'],\n",
    "                                         out[f'F1_{c}'],\n",
    "                                         out[f'IoU_{c}'],):\n",
    "                    \n",
    "                    tps.append(tp.unsqueeze(dim=0))\n",
    "                    tns.append(tn.unsqueeze(dim=0))\n",
    "                    fps.append(fp.unsqueeze(dim=0))\n",
    "                    fns.append(fn.unsqueeze(dim=0))\n",
    "                    \n",
    "                    precisions.append(precision.unsqueeze(dim=0))\n",
    "                    recalls.append(recall.unsqueeze(dim=0))\n",
    "                    f1s.append(f1.unsqueeze(dim=0))\n",
    "                    IoUs.append(iou.unsqueeze(dim=0))\n",
    "                    \n",
    "            tps = torch.cat(tps, dim=0).squeeze()\n",
    "            tns = torch.cat(tns, dim=0).squeeze()\n",
    "            fps = torch.cat(fps, dim=0).squeeze()\n",
    "            fns = torch.cat(fns, dim=0).squeeze()\n",
    "            \n",
    "            precisions = torch.cat(precisions, dim=0).squeeze()\n",
    "            recalls = torch.cat(recalls, dim=0).squeeze()\n",
    "            f1s = torch.cat(f1s, dim=0).squeeze()\n",
    "            IoUs = torch.cat(IoUs, dim=0).squeeze()\n",
    "            \n",
    "            \n",
    "            # logging \n",
    "            self.log(f'{mode}/epoch_TP_{c}', tps)\n",
    "            self.log(f'{mode}/epoch_TN_{c}', tns)\n",
    "            self.log(f'{mode}/epoch_FP_{c}', fps)\n",
    "            self.log(f'{mode}/epoch_FN_{c}', fns)\n",
    "            \n",
    "            self.log(f'{mode}/epoch_Precision_{c}', precisions)\n",
    "            self.log(f'{mode}/epoch_Recall_{c}', recalls)\n",
    "            \n",
    "            self.log(f'{mode}/epoch_F1_{c}', f1s)\n",
    "            self.log(f'{mode}/epoch_IoU_{c}', IoUs)\n",
    "            \n",
    "            mean_iou += np.mean(IoUs.numpy()).item()\n",
    "            mean_f1 += np.mean(f1s.numpy()).item()\n",
    "        \n",
    "        mean_iou /= cfg.model.out_channels\n",
    "        mean_f1 /= cfg.model.out_channels\n",
    "        self.log(f'{mode}/mean_IoU', mean_iou)\n",
    "        self.log(f'{mode}/mean_F1', mean_f1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "        scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **self.cfg.scheduler.params\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "### Fold: 0\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/syu/c983cccd-1cc7-4ce4-b206-7eb1a2cc5c94/topcoder/spacenet8/SpaceNet8/baseline/wandb/run-20220727_115513-sv6m3sa9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/syuchimu/SpaceNet8_foundation/runs/sv6m3sa9\" target=\"_blank\">3090_fold0</a></strong> to <a href=\"https://wandb.ai/syuchimu/SpaceNet8_foundation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start Trainig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | backbone   | UnetPlusPlus     | 50.5 M\n",
      "1 | _criterion | MultiBCEDiceLoss | 0     \n",
      "------------------------------------------------\n",
      "50.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.5 M    Total params\n",
      "101.057   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 640 image filepaths\n",
      "loaded 161 image filepaths\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdc512647dc4f958ae833871ee1ffff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bde876b8884d5b9b5094bdc686ba17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8f999d11e7452988d69caa31257887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f62111ac33042f5a246353277e437fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02929aea7e4046a7be03a8eb896c9ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e864fefa24f24539b456f23f1d330b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210ae146e0264dad8d8dd1c1e3e23635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ddb6f655a04a468a5dacaf6cbf8252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7cbc42aaff42ecb4ce17232ab3fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b513e738bce3468b9eabbf77fc2bf346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bcf9cd780d4786ae1ba6405be86f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081da201993e4326978e6f5a23825e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b6dcad1d03400eb060ced1fc4bd471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e5141005d84d6abd80c02ed201d30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0d3e9ce07b43008a20ea5e7b8f27f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74bc870dbc14f99b1f4cc6c95cbfb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f6df22c3942fc8298e6dc18d87f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71080e28798f4bffbaa9a6b1fb5312c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae3f5f9d32d432f94e0255aeb3e83bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08f1e1d81344588a7863e1de1cb7ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a77bb91de94eba964834693cd41022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa70bdec3834581ac4a30ab91491100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261d5cd09b904eafb2ee74a3bfb026b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93a31a014a34b63acbf2ca5b71bc734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948bf8d22a314f4d9bafa14ee1ba6696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377b85ff79d94874a51f51bef870c5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91531737e1745bfbc0fdc48bcce2c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5107985ac0450ea0279aefd2a2f48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784975822f45401f8520a70e54bd6f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc746af140c46a1956313b09809be54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cf7188c34f4eff84611a3582006373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ae155c28a74973b7d3133e75b4a2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf67658d4ac4f6c931c1bb635875124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded55c27a27f4948a5d9826d01188a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb775b5ebb474dfca6f1132fb5d6beea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17723c12316e4c9fbfe7dcab71916cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cb6a649a4946c8888b242bcc311377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923b87badbc446558dcf1e0b20478789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c05bff77c040f69a5b7f7ec2165a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8673e56cf3d04a67a1e62bf7fd31f7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f698ff1a45824413af46480b5bd3af30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bc6c0db3f8454aa3431707253c6853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347e008a749a406aab84865af2d774e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bfdc2157a4b9596d7616171fedf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea3d9245ca648bbb3286d16153adbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b879a5fcf8474db79bd41d51192b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fec9db13964cab8edb7f173a0c52c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adf071711ad45c58b4b130f1db3c095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f637026aa802405bbeb196a7c7cd55d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c746b0ae3540c9a5ded237230458ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c188a886607d42598c763a09e1fd0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a00c93945ac41f5acef985081354758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.063 MB of 1.124 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.946009…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-AdamW</td><td>██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁</td></tr><tr><td>train/epoch_F1_0</td><td>▁▅▅▆▆▇▇▇▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇████▇▇██████</td></tr><tr><td>train/epoch_F1_1</td><td>▁▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train/epoch_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_3</td><td>▁▂▃▃▄▄▅▅▄▄▅▅▆▆▆▆▆▅▆▆▆▆▇▇▆▆▆▇▇▇▇█▆▇▇▇████</td></tr><tr><td>train/epoch_F1_4</td><td>▁▁▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▅▆▆▆▆▇▇▆▆▆▇▇▇▇█▆▇▇▇▇███</td></tr><tr><td>train/epoch_F1_5</td><td>▁▁▁▁▂▃▄▄▄▄▅▆▆▆▆▆▅▅▅▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_F1_6</td><td>▁▁▁▁▁▁▁▂▂▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_0</td><td>█▆▅▄▃▃▃▃▄▄▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▁▁▁▁</td></tr><tr><td>train/epoch_FN_1</td><td>█▄▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_3</td><td>▇█▆▆▅▄▄▃▄▄▄▃▃▃▂▂▃▄▃▃▃▂▂▂▂▃▂▂▂▂▁▁▂▂▂▂▁▁▁▁</td></tr><tr><td>train/epoch_FN_4</td><td>▆█▅▄▃▃▃▃▃▃▃▃▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_5</td><td>▆████▇▆▅▅▅▄▃▃▃▃▃▃▃▃▃▂▂▂▂▃▃▂▂▂▂▂▁▂▂▂▂▁▁▁▁</td></tr><tr><td>train/epoch_FN_6</td><td>▆███████▇▅▃▂▂▁▁▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_0</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_1</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_2</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_4</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_5</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_6</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_8</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_0</td><td>▁▄▄▆▆▆▆▇▆▅▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train/epoch_IoU_1</td><td>▁▄▅▅▅▆▆▆▅▅▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████</td></tr><tr><td>train/epoch_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_3</td><td>▁▂▂▃▃▄▄▄▄▄▄▄▅▅▆▆▅▄▅▅▅▆▆▆▆▅▆▆▆▇▇▇▆▆▇▇▇▇██</td></tr><tr><td>train/epoch_IoU_4</td><td>▁▁▃▄▄▄▄▄▄▄▅▅▅▅▅▆▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇██</td></tr><tr><td>train/epoch_IoU_5</td><td>▁▁▁▁▁▂▃▄▄▄▄▅▅▅▆▆▅▅▅▆▆▆▇▆▆▅▆▆▆▇▇▇▆▆▇▇▇███</td></tr><tr><td>train/epoch_IoU_6</td><td>▁▁▁▁▁▁▁▁▂▄▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▆▇▇▇▆▇▇██</td></tr><tr><td>train/epoch_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_0</td><td>▁▄▅▆▆▆▆▇▆▅▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train/epoch_Precision_1</td><td>▁▅▅▅▆▆▆▆▆▅▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████</td></tr><tr><td>train/epoch_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_3</td><td>▁▂▃▃▄▄▄▄▄▄▅▅▅▆▆▆▅▅▅▆▆▆▆▇▆▆▆▇▇▇▇█▆▆▇▇████</td></tr><tr><td>train/epoch_Precision_4</td><td>▁▂▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▆▆▇▇▇███</td></tr><tr><td>train/epoch_Precision_5</td><td>▁▁▂▃▄▆▆▆▅▅▅▆▆▆▆▆▆▅▅▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_Precision_6</td><td>▁▁▂▂▂▂▄▆▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_0</td><td>▁▃▄▅▅▆▅▆▅▅▆▆▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇▇████</td></tr><tr><td>train/epoch_Recall_1</td><td>▁▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█████▇▇██████</td></tr><tr><td>train/epoch_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_3</td><td>▃▁▃▄▄▅▅▆▅▅▅▆▆▆▇▇▆▅▆▆▇▇▇▇▇▇▇▇▇███▇▇▇█████</td></tr><tr><td>train/epoch_Recall_4</td><td>▃▁▅▅▆▆▆▆▆▅▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█████</td></tr><tr><td>train/epoch_Recall_5</td><td>▃▁▁▁▁▂▃▄▄▅▅▆▆▆▇▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇█▇▇▇▇████</td></tr><tr><td>train/epoch_Recall_6</td><td>▃▁▁▁▁▁▁▁▂▄▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▆█▇▇▇▇▇██</td></tr><tr><td>train/epoch_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TN_0</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_1</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_2</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_3</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_4</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_5</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_6</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_7</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TP_0</td><td>▁▃▄▅▆▆▆▆▆▅▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇████▇▇▇▇████</td></tr><tr><td>train/epoch_TP_1</td><td>▁▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█████▇▇██████</td></tr><tr><td>train/epoch_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_3</td><td>▂▁▃▃▄▅▅▆▅▅▅▆▆▆▇▇▆▅▆▆▆▇▇▇▇▆▇▇▇▇██▇▇▇▇████</td></tr><tr><td>train/epoch_TP_4</td><td>▃▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█████</td></tr><tr><td>train/epoch_TP_5</td><td>▃▁▁▁▁▂▃▄▄▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇█▇▇▇▇████</td></tr><tr><td>train/epoch_TP_6</td><td>▃▁▁▁▁▁▁▁▂▄▆▇▇███▇▇▇██████▇██████▇███████</td></tr><tr><td>train/epoch_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_build</td><td>█▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_speed</td><td>█▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▂▂▁▂▁▁▂▂▂▁▁▁▁▂▁▂▁▁▁▁▁</td></tr><tr><td>train/iter_F1_0</td><td>▁▂▃▆▃▇▆▄▄▆▅▅▆▆▅▅▃▅▆▆▇▆▆▅▇▇▆▇▇▇▇▆▇▆█▆▆▆▅▅</td></tr><tr><td>train/iter_F1_1</td><td>▁▅▆▆▅▆▇▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇▇▇█</td></tr><tr><td>train/iter_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_3</td><td>▁▂▄▅▃▅▃▃▃▄▅▅▆▇▇▄▄▇▅▅▆▅▇▅▇▆▆▇▇▇▇█▇▇▇▆▇███</td></tr><tr><td>train/iter_F1_4</td><td>▁▃▃▃▆▂▆▅▆▆▆▆▇▄▇▇▅▇▇▆█▇██▁▆▇█▇▇▇▆▇▇█▇█▇██</td></tr><tr><td>train/iter_F1_5</td><td>▁▁▁▁▁▁▁▇▃▅▃▁▇█▆▆▆█▆▆▆▁▁▇█▁▂▇▇▃▆▆▇▁█▆█▆▄█</td></tr><tr><td>train/iter_F1_6</td><td>▁▁▁▁▁▁▂▂▂▆▆▂▁▁▁█▁▁█▄██▁▇▁█▁█▁▁▇▁▄█▅█▁█▁█</td></tr><tr><td>train/iter_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_0</td><td>▅▃▃▆▆▂▅▂▂▃▂▃▂▁▂▃▃▁▆▃▂▃▆▃▁▃▂▂▁▂▄▁█▂▁▃▄▃▂▂</td></tr><tr><td>train/iter_FN_1</td><td>█▃▃▂▃▂▂▂▂▂▃▂▁▂▂▂▂▁▂▂▂▂▂▁▂▃▂▁▂▁▂▁▂▂▁▃▁▂▂▂</td></tr><tr><td>train/iter_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_3</td><td>▅▇█▆▂▅▂▂▃▆▆▄▂▃▅▃▂▃▂▂▂▃▂▁▃█▃▁▄▂▂▂▃▃▂▆▁▂▃▂</td></tr><tr><td>train/iter_FN_4</td><td>█▅▄▂▆▄▆▂▂▂▅▂▂▁▂▂▅▁▄▇▃▃▄▃▁▃▂▂▂▃▃▁▃▅▂▆▃▂▂▂</td></tr><tr><td>train/iter_FN_5</td><td>█▇▃█▃▁▃▂▄▁▂▁▁▂▂▅▃▁▂▁▁▁▁▁▂▁▁▁▂▃▁▁▂▁▁▂▁▂▁▁</td></tr><tr><td>train/iter_FN_6</td><td>█▁▇▁▄▆▆▇▃▃▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_0</td><td>▅▃▃▃▇▁▄▄▂▆▃▇▃▁▂▅▄▄▄▃▃▅█▆▁▄▂▂▁▁▅▁▄▃▁▄▅▃▂▄</td></tr><tr><td>train/iter_FP_1</td><td>▁▄▅▅█▅▅▅▄▆▄▅▃▃▄▄▃▃▃▃▃▄▄▄▂▅▄▃▂▂▅▂▄▃▃▃▃▄▂▂</td></tr><tr><td>train/iter_FP_2</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_3</td><td>▁▃▄▄█▅▆▅▅▄▆▃▃▃▄▄▂▃▃▄▃▃▃▃▂▃▄▃▂▄▃▂▄▄▃▄▂▃▂▂</td></tr><tr><td>train/iter_FP_4</td><td>▁▃▅▇▇▅▅▅▃█▃▆▄▂▂▅▃▂▅▂▃▅▇▅▃▆▃▃▂▂▆▂▅▂▁▃▅▄▂▃</td></tr><tr><td>train/iter_FP_5</td><td>▁▁▁▁▁▁▅▂▃▆▄▅▂▂▆▃▄▂▄█▃▁▂▃▃▆▆▃▃▁▄▄▂▂▃▅▃▃▂▂</td></tr><tr><td>train/iter_FP_6</td><td>▁▁▁▁▁▁▁▁▅▅▅▅▁▁▃▆▃▂▅▁▇▄▁▇▁█▁▃▁▁▂▁▆█▁▂▁▆▁▂</td></tr><tr><td>train/iter_FP_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_8</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_0</td><td>▁▂▃▆▂▇▆▄▄▅▅▄▆▆▄▅▃▅▅▆▇▅▆▅▆▇▆▇▇▇▇▆▇▆█▆▆▆▅▅</td></tr><tr><td>train/iter_IoU_1</td><td>▁▄▅▅▄▅▆▅▅▅▆▅▆▆▇▇▅▇▇▇▇▆▇▇▆▆▆▇▇█▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/iter_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_3</td><td>▁▂▃▄▃▄▃▃▃▃▄▄▅▆▆▃▃▇▅▄▅▄▆▄▆▅▆▆▆▇▆█▆▇▇▆▆███</td></tr><tr><td>train/iter_IoU_4</td><td>▁▂▂▂▅▂▆▅▅▅▅▆▆▃▆▇▄▆▆▅█▇██▁▅▇█▇▆▇▅▇▇█▇█▇▇█</td></tr><tr><td>train/iter_IoU_5</td><td>▁▁▁▁▁▁▁▆▂▄▂▁▇█▅▅▆█▅▅▅▁▁▆█▁▁▇▇▃▅▆▇▁█▅▇▅▃█</td></tr><tr><td>train/iter_IoU_6</td><td>▁▁▁▁▁▁▂▂▂▅▅▂▁▁▁▇▁▁▇▃▇█▁▇▁█▁█▁▁▇▁▃▇▄█▁█▁█</td></tr><tr><td>train/iter_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_0</td><td>▁▂▃▇▂▇▆▄▄▅▅▄▅▅▄▄▃▄▆▆▆▅▅▅▆▇▅▇▇▇▆▅█▆█▆▆▆▅▄</td></tr><tr><td>train/iter_Precision_1</td><td>▁▄▅▅▄▅▆▅▅▅▆▅▆▇▇▇▅▆▇▇▇▆▇▇▇▆▆▇██▆▇▇▇▇█▇▇▇█</td></tr><tr><td>train/iter_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_3</td><td>▁▃▄▅▃▅▃▃▃▄▄▄▆▇▇▄▃▇▅▄▅▅▆▄▇▇▆▆▇▇▆█▆▇▇▇▆███</td></tr><tr><td>train/iter_Precision_4</td><td>▂▃▂▂▅▂▆▄▅▄▅▅▅▃▅▆▅▅▆▇▇▆▇▆▁▅▆▇▇▇▆▄▆▇█▇▆▆▆▇</td></tr><tr><td>train/iter_Precision_5</td><td>▁▁▁▂▄▁▁█▃▄▃▁▆█▅▇▆▇▅▅▅▁▁▆█▁▁▆▇▆▅▅▇▁▇▅▇▅▃▇</td></tr><tr><td>train/iter_Precision_6</td><td>▁▁▁▁▁▁██▂▆▆▂▁▁▁▇▁▁▇▄▇▇▁▆▁▇▁▇▁▁▆▁▃▇▄▇▁▇▁█</td></tr><tr><td>train/iter_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_0</td><td>▁▁▂▃▄▆▅▆▄▇▆▇▇▇▆▆▄█▄▆▇▇▆▇▇▆▆▇▇▅▇▇▅▇▇▆▇▆▅▇</td></tr><tr><td>train/iter_Recall_1</td><td>▁▅▆▇▇▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇██▇▇▇█▇███▇▇█▇██▇█</td></tr><tr><td>train/iter_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_3</td><td>▁▂▃▅▆▅▆▅▄▄▅▅▇▇▆▅▅▇▆▆▆▅▇█▆▅▇█▆▇▇▇▇▇▇▆█▇▇▇</td></tr><tr><td>train/iter_Recall_4</td><td>▁▂▃▅▆▃▆▇▆█▅█▇▇▇█▄█▇▄▇▇██▁▇▇█▇▅██▇▆▆▆████</td></tr><tr><td>train/iter_Recall_5</td><td>▁▁▁▁▁▁▁▅▂▇▃▁█▇▇▄▆█▆█▇▁▁█▇▁██▆▂▇█▆▁█▆▇▆▆█</td></tr><tr><td>train/iter_Recall_6</td><td>▁▁▁▁▁▁▂▂▂▆▅█▁▁▁█▁▁█▄▇█▁█▁█▁█▁▁█▁▇█▇█▁█▁▇</td></tr><tr><td>train/iter_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TN_0</td><td>▆▇▇▆▄▇▅▆▇▄▆▄▇█▇▅▆▆▄▆▅▅▁▄█▅▇▆██▃█▃▆█▅▄▅▇▆</td></tr><tr><td>train/iter_TN_1</td><td>▆▅▄▄▁▄▃▅▅▂▃▄▆▆▄▄▆▆▄▅▅▃▂▄▇▁▅▆▆▆▃█▃▃▆▂▅▄▆▅</td></tr><tr><td>train/iter_TN_2</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/iter_TN_3</td><td>█▅▃▃▁▃▄▄▄▄▁▅▅▄▂▅▇▄▆▅▆▅▆▇▅▂▄▇▅▄▅▆▄▃▅▂█▄▅▆</td></tr><tr><td>train/iter_TN_4</td><td>▇▇▆▅▃▆▄▅▇▄▆▄▆█▇▅▆▇▄▆▆▄▁▄█▅▆▆▇▇▃█▄▆█▅▄▆▇▅</td></tr><tr><td>train/iter_TN_5</td><td>▄▄▇▄▇█▅▆▅▄▅▆▆▄▃▂▂▆▄▁▆█▇▆▃▅▅▅▄▆▅▅▅█▅▃▅▅▇▆</td></tr><tr><td>train/iter_TN_6</td><td>▅█▆█▇▆▆▅▆▄▅▇██▇▄▇█▄█▁▄█▄█▁█▅██▇█▆▁█▇█▃█▇</td></tr><tr><td>train/iter_TN_7</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/iter_TN_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/iter_TP_0</td><td>▂▁▂▃▄▂▄▂▁▅▃▅▂▁▁▄▂▃▅▃▄▄█▅▁▅▂▃▁▁▆▁▇▄▂▄▆▄▂▃</td></tr><tr><td>train/iter_TP_1</td><td>▁▃▄▅▅▄▆▄▄▆▆▅▄▄▆▆▄▅▆▅▆▆█▆▄▇▅▅▅▅▇▃▇▇▄█▅▇▅▆</td></tr><tr><td>train/iter_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_3</td><td>▁▂▃▅▄▅▃▃▃▃▆▃▅▇█▃▂▇▃▄▃▄▄▂▅▇▆▄▆█▆▅▆█▆█▃█▇▅</td></tr><tr><td>train/iter_TP_4</td><td>▁▁▁▁▄▁▄▃▂▄▂▄▃▁▂▄▂▂▅▂▄▅█▅▁▃▃▃▂▂▅▁▅▃▂▄▅▃▃▄</td></tr><tr><td>train/iter_TP_5</td><td>▁▁▁▁▁▁▁▃▂▄▂▁▃█▆▆▇▄▄▇▂▁▁▄█▁▁▄▆▂▄▄▅▁▅▆▆▃▁▄</td></tr><tr><td>train/iter_TP_6</td><td>▁▁▁▁▁▁▁▁▁▄▃▁▁▁▁▅▁▁▅▁▇▅▁▅▁█▁▄▁▁▂▁▂█▁▃▁▆▁▂</td></tr><tr><td>train/iter_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_loss</td><td>█▆█▅▇▅▇▇█▇▇▇▅▅▅▇▅▅▇▇▇▄▁▆▃▄▅▇▅▅▆▅▆▄▇▇▄▇▅▇</td></tr><tr><td>train/iter_loss_build</td><td>███▆▆▇▄▇█▄▆▅▆█▇▅▇▆▄▅▄▄▁▄█▄▇▅██▂█▂▅▇▅▃▅▇▆</td></tr><tr><td>train/iter_loss_speed</td><td>█▅█▄█▄██████▄▄▄▇▄▄▇▇▇▄▁▇▁▄▄▇▄▄▇▄▇▄▇▇▄▇▄▇</td></tr><tr><td>train/mean_F1</td><td>▁▂▃▄▄▄▅▅▅▅▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████</td></tr><tr><td>train/mean_IoU</td><td>▁▂▃▃▄▄▄▄▄▄▅▅▆▆▆▆▆▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▆▇▇▇▇███</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/epoch_F1_0</td><td>▁▆▃▆▅▆▆▆▅▅▄▄▇▇█▇▆▆▆▇▆▆▇▇▇▆█▇█▇██▇▆▆▇▇▇██</td></tr><tr><td>val/epoch_F1_1</td><td>▅▆▁▆▆▇▇▇▇▇▇▇████▇▇███▇██▇▇█▇████▇▇██████</td></tr><tr><td>val/epoch_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_3</td><td>▁▄▂▄▆▆▆▇▅▆▆▇▇▇▇▇▅▇▇▇▇▇██▆▇▇▇▇▇██▇▇█▇████</td></tr><tr><td>val/epoch_F1_4</td><td>▁▅▂▆▆▇▆▆▆▆▆▇▇▇▇▇▅▆▆▇▇▇▇▇▇▇▇▇▇███▇█▇█████</td></tr><tr><td>val/epoch_F1_5</td><td>▁▁▁▁▂▄▅▅▄▅▅▆▇▇▇▇▃▆▇▇▇▇▇▇▆▇▇▇████▇▇▇█████</td></tr><tr><td>val/epoch_F1_6</td><td>▁▁▁▁▁▁▁▂▄▅▇▇▇▇▇▇▆▇▇▇█▇██▇███████▇▇██████</td></tr><tr><td>val/epoch_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_0</td><td>▄▄█▃▂▂▂▃▃▂▁▁▃▂▂▂▃▂▂▂▂▂▂▂▃▂▄▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val/epoch_FN_1</td><td>█▄▄▄▂▂▂▂▃▃▂▂▂▂▂▂▄▁▃▂▂▁▂▂▃▁▃▂▁▂▂▂▁▁▂▂▂▂▂▂</td></tr><tr><td>val/epoch_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_3</td><td>█▆▇▅▂▂▃▃▃▅▂▃▂▂▂▂▃▂▃▃▂▂▂▂▄▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>val/epoch_FN_4</td><td>█▄▅▂▂▂▂▂▄▃▂▂▂▂▂▂▄▂▄▂▂▁▂▁▂▂▃▂▁▂▂▂▁▂▂▂▁▁▂▁</td></tr><tr><td>val/epoch_FN_5</td><td>████▇▆▄▅▆▃▅▃▃▃▂▂▇▃▂▂▂▂▂▂▄▁▂▂▁▁▁▁▂▁▂▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_6</td><td>████████▃▂▃▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_0</td><td>█▃▁▄▆▅▄▃▅▅▆▇▂▄▂▃▄▃▄▃▄▃▃▃▃▄▁▃▂▃▂▂▃▄▄▃▃▃▂▂</td></tr><tr><td>val/epoch_FP_1</td><td>▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_2</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_3</td><td>▁▂█▃▄▄▃▃▄▂▃▂▃▂▂▃▃▃▂▂▂▃▂▂▂▄▃▃▂▂▂▂▃▄▃▃▂▂▂▂</td></tr><tr><td>val/epoch_FP_4</td><td>▁▂█▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val/epoch_FP_5</td><td>▁▁▁▁▂▂▄▃▄█▃▄▃▄▄▄▁▆▆▄▆▅▄▄▂▇▄▃▄▅▅▄▅▅▄▄▃▄▄▄</td></tr><tr><td>val/epoch_FP_6</td><td>▁▁▁▁▁▁▁▁██▂▃▂▂▃▂▅▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂</td></tr><tr><td>val/epoch_FP_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_8</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_0</td><td>▁▅▃▆▄▅▆▆▅▅▄▄▇▆▇▇▅▆▆▇▆▆▆▇▆▆█▇█▇██▇▆▆▇▇▇██</td></tr><tr><td>val/epoch_IoU_1</td><td>▄▅▁▆▆▇▇▇▆▇▇▇▇██▇▇▇███▇██▇▇█▇▇███▇▇██████</td></tr><tr><td>val/epoch_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_3</td><td>▁▃▂▄▅▆▆▆▅▆▆▆▇▇▇▇▅▇▇▇▇▇██▆▆▇▇▇▇██▇▆▇▇████</td></tr><tr><td>val/epoch_IoU_4</td><td>▁▅▂▅▅▆▆▆▅▆▆▆▆▇▇▇▅▆▆▇▇▇▇▇▆▇▇▇▇▇██▇▇▇█████</td></tr><tr><td>val/epoch_IoU_5</td><td>▁▁▁▁▂▄▄▄▃▄▄▆▆▆▆▇▃▅▆▆▆▇▇▇▆▆▇▇█▇▇█▇▇▇▇████</td></tr><tr><td>val/epoch_IoU_6</td><td>▁▁▁▁▁▁▁▁▄▄▆▇▇▇▆▇▅▆▆▇▇▇██▆█▇█▇███▇▆▇▇████</td></tr><tr><td>val/epoch_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_0</td><td>▁▆▇▅▃▄▅▆▄▄▃▃▇▅▆▆▅▅▅▆▅▅▆▆▆▅█▆▆▅▇▆▆▄▅▆▆▆▆▆</td></tr><tr><td>val/epoch_Precision_1</td><td>▅▅▁▆▅▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆█▇▇▇▇█▆▆▇▇▇██▇</td></tr><tr><td>val/epoch_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_3</td><td>▁▃▁▄▄▅▆▆▄█▆▇▆▇▇▆▅▆▇▇▇▆▇▇▆▅▆▆▇▇▇▇▆▅▇▆▇███</td></tr><tr><td>val/epoch_Precision_4</td><td>▁▄▁▄▄▅▄▅▆▆▅▅▅▅▆▅▆▅▇▆▆▅▆▆▅▇█▆▅▆▆▆▅▇▆▇▆▆▇▇</td></tr><tr><td>val/epoch_Precision_5</td><td>▁▁▁▃▆▇▆▆▅▅▇▇▇▇▇▇▇▅▆▇▆▇▇▇█▆▇█▇▇▇▇▇▆▇▇█▇▇▇</td></tr><tr><td>val/epoch_Precision_6</td><td>▁▁▁▂▃▆▇█▄▄▆▇▇▇▆▇▅▆▆▇▇▇▇▇▆▇▇█▇███▇▆▇▇████</td></tr><tr><td>val/epoch_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_0</td><td>▅▅▁▆▇▇▇▆▆▇██▆▇▇▇▆▇▇▇▇▆▇▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/epoch_Recall_1</td><td>▁▅▅▅▇▇▇▇▅▆▇▆▇▇▇▇▅█▆▆▇▇▇▇▆█▆▇█▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val/epoch_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_3</td><td>▁▃▂▄▇▇▆▆▆▄▇▅▇▇▆▇▅▇▆▆▆▇▆▆▅█▇▇▇▇▇▆▇█▇▇▇▇▇▇</td></tr><tr><td>val/epoch_Recall_4</td><td>▁▅▄▇▇▇▇▇▅▆▇▇▇▇▇▇▄▇▅▇▇▇▇█▇▇▅▇█▇▇▇▇▇▇▇██▇█</td></tr><tr><td>val/epoch_Recall_5</td><td>▁▁▁▁▂▃▅▄▃▆▄▆▆▆▇▇▂▆▇▇█▇▇▇▅█▇▇████▇█▇█████</td></tr><tr><td>val/epoch_Recall_6</td><td>▁▁▁▁▁▁▁▁▆▇▇▇████▇▇██████▇███████▇███████</td></tr><tr><td>val/epoch_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_0</td><td>▁▆█▅▃▄▅▆▄▄▃▂▇▅▇▆▅▆▅▆▅▆▆▆▆▅█▆▇▆▇▇▆▅▅▆▆▆▇▇</td></tr><tr><td>val/epoch_TN_1</td><td>██▁█▇███████████████████████████████████</td></tr><tr><td>val/epoch_TN_2</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/epoch_TN_3</td><td>█▇▁▆▅▅▆▆▅▇▆▇▆▇▇▆▆▆▇▇▇▆▇▇▇▅▆▆▇▇▇▇▆▅▆▆▇▇▇▇</td></tr><tr><td>val/epoch_TN_4</td><td>█▇▁▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/epoch_TN_5</td><td>████▇▇▅▆▅▁▆▅▆▅▅▅█▃▃▅▃▄▅▅▇▂▅▆▅▄▄▅▄▄▅▅▆▅▅▅</td></tr><tr><td>val/epoch_TN_6</td><td>████████▁▁▇▆▇▇▆▇▄▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>val/epoch_TN_7</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/epoch_TN_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/epoch_TP_0</td><td>▅▅▁▆▇▇▇▆▆▇██▆▇▇▇▆▇▇▇▇▇▇▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/epoch_TP_1</td><td>▁▅▅▅▇▇▇▇▆▆▇▇▇▇▇▇▅█▆▇▇█▇▇▆█▆▇█▇▇▇██▇▇▇▇▇▇</td></tr><tr><td>val/epoch_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_3</td><td>▁▃▂▄▇▇▆▆▆▄▇▆▇▇▇▇▆▇▆▆▇▇▇▇▅█▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val/epoch_TP_4</td><td>▁▅▄▇▇▇▇▇▅▆▇▇▇▇▇▇▅▇▅▇▇█▇█▇▇▆▇█▇▇▇█▇▇▇██▇█</td></tr><tr><td>val/epoch_TP_5</td><td>▁▁▁▁▂▃▅▄▃▆▄▆▆▆▇▇▂▆▇▇▇▇▇▇▅█▇▇████▇█▇█████</td></tr><tr><td>val/epoch_TP_6</td><td>▁▁▁▁▁▁▁▁▆▇▆▇████▇▇██████████████▇███████</td></tr><tr><td>val/epoch_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss</td><td>▅▃█▂▂▁▂▂▂▂▂▂▁▁▁▁▂▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val/epoch_loss_build</td><td>▆▄█▂▂▁▂▂▃▂▂▂▁▁▁▁▃▂▂▂▂▁▂▁▃▂▂▁▁▁▁▁▂▂▂▁▁▂▁▂</td></tr><tr><td>val/epoch_loss_speed</td><td>▄▂█▂▂▂▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_0</td><td>▁▆▃▆▄▆▆▆▅▅▄▄▇▇█▇▆▆▆▇▆▆▇▇▆▆█▇█▇██▇▆▆▇▇▇██</td></tr><tr><td>val/iter_F1_1</td><td>▅▆▁▇▆▇▇▇▇▇▇▇████▇▇███▇██▇▇█▇████▇▇██████</td></tr><tr><td>val/iter_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_3</td><td>▁▃▂▄▆▆▆▆▅▆▆▇▇▇▇▇▅▇▇▇▇▇██▆▇▇▇▇▇██▇▇▇▇████</td></tr><tr><td>val/iter_F1_4</td><td>▁▅▂▆▆▆▆▆▆▆▆▇▇▇▇▇▅▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇█████</td></tr><tr><td>val/iter_F1_5</td><td>▁▁▁▁▂▄▅▅▄▅▅▆▇▇▇▇▃▆▇▇▇▇▇▇▆▇▇▇████▇▇▇█████</td></tr><tr><td>val/iter_F1_6</td><td>▁▁▁▁▁▁▁▂▄▅▇▇▇▇▇▇▆▇▇▇█▇██▇███████▇▇██████</td></tr><tr><td>val/iter_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_0</td><td>▄▄█▃▂▂▂▃▃▂▁▁▃▂▂▂▃▂▂▂▂▂▂▂▃▂▄▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val/iter_FN_1</td><td>█▄▄▄▂▂▂▂▃▃▂▂▂▂▂▂▄▁▂▂▂▁▂▂▃▁▃▂▁▂▂▂▁▁▂▂▂▂▂▂</td></tr><tr><td>val/iter_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_3</td><td>█▆▇▅▂▂▃▃▃▅▂▃▂▂▂▂▃▂▃▃▂▂▂▂▄▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>val/iter_FN_4</td><td>█▄▅▂▂▂▂▂▄▃▂▂▂▂▂▂▄▂▄▂▂▁▂▁▂▂▃▂▁▂▂▂▁▂▂▂▁▁▂▁</td></tr><tr><td>val/iter_FN_5</td><td>████▇▆▄▅▆▃▅▃▃▃▂▂▇▃▂▂▂▂▂▂▄▁▂▂▁▁▁▁▂▁▂▁▁▁▁▁</td></tr><tr><td>val/iter_FN_6</td><td>████████▃▂▃▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_0</td><td>█▃▁▄▆▅▄▃▅▅▆▇▂▄▂▃▄▃▄▃▄▃▃▃▃▄▁▃▃▃▂▃▃▄▄▃▃▃▂▂</td></tr><tr><td>val/iter_FP_1</td><td>▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_2</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_3</td><td>▁▂█▃▄▄▃▃▄▂▃▂▃▂▂▃▃▃▂▂▂▃▂▂▂▄▃▃▂▂▂▂▃▄▃▃▂▂▂▂</td></tr><tr><td>val/iter_FP_4</td><td>▁▂█▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val/iter_FP_5</td><td>▁▁▁▁▂▂▄▃▄█▃▄▃▄▄▄▁▆▆▄▆▅▄▄▂▇▄▃▄▅▅▄▅▅▄▄▃▄▄▄</td></tr><tr><td>val/iter_FP_6</td><td>▁▁▁▁▁▁▁▁██▂▃▂▂▃▂▅▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂</td></tr><tr><td>val/iter_FP_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_8</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_0</td><td>▁▅▂▆▄▅▆▆▅▅▄▄▇▆▇▇▅▆▆▇▆▆▆▇▆▆█▇█▇██▇▆▆▇▇▇██</td></tr><tr><td>val/iter_IoU_1</td><td>▄▅▁▆▆▇▇▇▆▇▇▇▇██▇▇▇███▇██▇▇█▇████▇▇██████</td></tr><tr><td>val/iter_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_3</td><td>▁▃▂▄▅▅▆▆▅▆▆▆▇▇▇▇▅▆▇▇▇▇█▇▆▆▇▇▇▇██▇▆▇▇████</td></tr><tr><td>val/iter_IoU_4</td><td>▁▅▂▅▅▆▆▆▅▆▆▆▆▇▇▇▅▆▆▇▇▇▇▇▆▇▇▇▇▇██▇▇▇█████</td></tr><tr><td>val/iter_IoU_5</td><td>▁▁▁▁▂▄▄▄▃▄▄▆▆▆▆▇▃▅▆▆▆▇▇▇▆▆▇▇█▇▇█▇▇▇▇████</td></tr><tr><td>val/iter_IoU_6</td><td>▁▁▁▁▁▁▁▁▄▄▆▇▇▇▆▇▅▆▆▇▇▇██▆█▇█▇███▇▆▇▇████</td></tr><tr><td>val/iter_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_0</td><td>▁▆▇▅▃▄▅▅▄▄▃▃▇▅▆▆▅▅▅▆▅▅▅▆▆▅█▆▆▅▆▆▆▄▅▆▆▆▆▆</td></tr><tr><td>val/iter_Precision_1</td><td>▅▆▁▆▆▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇█▇▇▆█▇▇▇▇█▆▆▇▇▇███</td></tr><tr><td>val/iter_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_3</td><td>▁▃▁▄▄▅▅▆▄█▅▇▆▇▇▆▅▆▇▇▇▇▇▇▆▅▇▆▇▇▇█▆▅▇▇▇███</td></tr><tr><td>val/iter_Precision_4</td><td>▁▄▁▄▄▅▅▅▆▆▅▅▅▆▆▅▆▅▇▆▆▆▆▆▆▇█▆▅▆▆▆▅▇▆▇▆▇▇▇</td></tr><tr><td>val/iter_Precision_5</td><td>▁▁▁▃▆▇▆▆▅▅▇▇▇▇▇▇▇▅▆▇▆▇▇▇█▆▇█▇▇▇▇▇▆▇▇█▇▇▇</td></tr><tr><td>val/iter_Precision_6</td><td>▁▁▁▂▃▆▇█▄▄▆▇▇▇▆▇▅▆▆▇▇▇▇▇▆▇▇█▇███▇▆▇▇████</td></tr><tr><td>val/iter_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_0</td><td>▅▅▁▆▇▇▇▆▆▇██▆▇▇▇▆▇▇▇▇▆▇▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/iter_Recall_1</td><td>▁▅▅▅▇▇▇▇▆▆▇▇▇▇▇▇▅█▆▆▇█▇▇▆█▆▇█▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val/iter_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_3</td><td>▁▃▂▄▇▇▆▆▆▄▇▅▇▇▆▇▅▇▆▆▇▇▇▇▅█▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val/iter_Recall_4</td><td>▁▅▄▇▇▇▇▇▅▆▇▇▇▇▇▇▄▇▅▇▇▇▇█▇▆▆▇█▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>val/iter_Recall_5</td><td>▁▁▁▁▂▃▅▄▃▆▄▆▆▆▇▇▂▆▇▇█▇▇▇▅█▇▇████▇█▇█████</td></tr><tr><td>val/iter_Recall_6</td><td>▁▁▁▁▁▁▁▁▆▇▇▇████▇▇██████▇███████▇███████</td></tr><tr><td>val/iter_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_0</td><td>▁▆█▅▃▄▅▆▄▄▃▂▇▅▇▆▅▆▅▆▅▆▆▆▆▅█▆▆▆▇▆▆▅▅▆▆▆▇▇</td></tr><tr><td>val/iter_TN_1</td><td>██▁█▇███████████████████████████████████</td></tr><tr><td>val/iter_TN_2</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/iter_TN_3</td><td>█▇▁▆▅▅▆▆▅▇▆▇▆▇▇▆▆▆▇▇▇▆▇▇▇▅▆▆▇▇▇▇▆▅▆▆▇▇▇▇</td></tr><tr><td>val/iter_TN_4</td><td>█▇▁▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/iter_TN_5</td><td>████▇▇▅▆▅▁▆▅▆▅▅▅█▃▃▅▃▄▅▅▇▂▅▆▅▄▄▅▄▄▅▅▆▅▅▅</td></tr><tr><td>val/iter_TN_6</td><td>████████▁▁▇▆▇▇▆▇▄▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>val/iter_TN_7</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/iter_TN_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>val/iter_TP_0</td><td>▅▅▁▆▇▇▇▆▆▇██▆▇▇▇▆▇▇▇▇▇▇▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/iter_TP_1</td><td>▁▅▅▅▇▇▇▇▆▆▇▇▇▇▇▇▅█▇▇▇█▇▇▆█▆▇█▇▇▇██▇▇▇▇▇▇</td></tr><tr><td>val/iter_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_3</td><td>▁▃▂▄▇▇▆▆▆▄▇▆▇▇▇▇▆▇▆▆▇▇▇▇▅█▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val/iter_TP_4</td><td>▁▅▄▇▇▇▇▇▅▆▇▇▇▇▇▇▅▇▅▇▇█▇█▇▇▆▇█▇▇▇█▇▇▇██▇█</td></tr><tr><td>val/iter_TP_5</td><td>▁▁▁▁▂▃▅▄▃▆▄▆▆▆▇▇▂▆▇▇▇▇▇▇▅█▇▇████▇█▇█████</td></tr><tr><td>val/iter_TP_6</td><td>▁▁▁▁▁▁▁▁▆▇▆▇████▇▇██████████████▇███████</td></tr><tr><td>val/iter_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss</td><td>▄▃█▂▂▁▂▂▂▂▂▂▁▁▁▁▂▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val/iter_loss_build</td><td>▆▄█▂▂▁▂▂▃▂▂▂▁▁▁▁▃▁▂▁▂▁▂▂▃▂▂▁▁▂▁▁▂▂▂▁▁▂▂▂</td></tr><tr><td>val/iter_loss_speed</td><td>▄▂█▂▂▂▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mean_F1</td><td>▁▃▁▄▄▅▅▆▅▆▆▆▇▇▇▇▅▆▇▇▇▇█▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>val/mean_IoU</td><td>▁▃▁▃▄▅▅▅▅▅▅▆▇▇▇▇▅▆▆▇▇▇▇▇▆▇▇▇▇███▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-AdamW</td><td>2e-05</td></tr><tr><td>train/epoch_F1_0</td><td>0.82772</td></tr><tr><td>train/epoch_F1_1</td><td>0.79131</td></tr><tr><td>train/epoch_F1_2</td><td>0.0</td></tr><tr><td>train/epoch_F1_3</td><td>0.73161</td></tr><tr><td>train/epoch_F1_4</td><td>0.72683</td></tr><tr><td>train/epoch_F1_5</td><td>0.67084</td></tr><tr><td>train/epoch_F1_6</td><td>0.52681</td></tr><tr><td>train/epoch_F1_7</td><td>0.0</td></tr><tr><td>train/epoch_F1_8</td><td>0.0</td></tr><tr><td>train/epoch_FN_0</td><td>1832.48755</td></tr><tr><td>train/epoch_FN_1</td><td>3186.375</td></tr><tr><td>train/epoch_FN_2</td><td>0.0</td></tr><tr><td>train/epoch_FN_3</td><td>2270.44995</td></tr><tr><td>train/epoch_FN_4</td><td>1734.61255</td></tr><tr><td>train/epoch_FN_5</td><td>621.35004</td></tr><tr><td>train/epoch_FN_6</td><td>189.0125</td></tr><tr><td>train/epoch_FN_7</td><td>0.0</td></tr><tr><td>train/epoch_FN_8</td><td>0.0</td></tr><tr><td>train/epoch_FP_0</td><td>11809.15039</td></tr><tr><td>train/epoch_FP_1</td><td>20744.0625</td></tr><tr><td>train/epoch_FP_2</td><td>0.0</td></tr><tr><td>train/epoch_FP_3</td><td>10886.8623</td></tr><tr><td>train/epoch_FP_4</td><td>9085.9873</td></tr><tr><td>train/epoch_FP_5</td><td>2384.9126</td></tr><tr><td>train/epoch_FP_6</td><td>1369.6875</td></tr><tr><td>train/epoch_FP_7</td><td>0.0</td></tr><tr><td>train/epoch_FP_8</td><td>0.0</td></tr><tr><td>train/epoch_IoU_0</td><td>0.71507</td></tr><tr><td>train/epoch_IoU_1</td><td>0.65556</td></tr><tr><td>train/epoch_IoU_2</td><td>0.0</td></tr><tr><td>train/epoch_IoU_3</td><td>0.58104</td></tr><tr><td>train/epoch_IoU_4</td><td>0.58019</td></tr><tr><td>train/epoch_IoU_5</td><td>0.5476</td></tr><tr><td>train/epoch_IoU_6</td><td>0.44855</td></tr><tr><td>train/epoch_IoU_7</td><td>0.0</td></tr><tr><td>train/epoch_IoU_8</td><td>0.0</td></tr><tr><td>train/epoch_Precision_0</td><td>0.74232</td></tr><tr><td>train/epoch_Precision_1</td><td>0.68639</td></tr><tr><td>train/epoch_Precision_2</td><td>0.0</td></tr><tr><td>train/epoch_Precision_3</td><td>0.62327</td></tr><tr><td>train/epoch_Precision_4</td><td>0.62064</td></tr><tr><td>train/epoch_Precision_5</td><td>0.5885</td></tr><tr><td>train/epoch_Precision_6</td><td>0.47462</td></tr><tr><td>train/epoch_Precision_7</td><td>0.0</td></tr><tr><td>train/epoch_Precision_8</td><td>0.0</td></tr><tr><td>train/epoch_Recall_0</td><td>0.95112</td></tr><tr><td>train/epoch_Recall_1</td><td>0.93614</td></tr><tr><td>train/epoch_Recall_2</td><td>0.0</td></tr><tr><td>train/epoch_Recall_3</td><td>0.89415</td></tr><tr><td>train/epoch_Recall_4</td><td>0.89244</td></tr><tr><td>train/epoch_Recall_5</td><td>0.79767</td></tr><tr><td>train/epoch_Recall_6</td><td>0.60591</td></tr><tr><td>train/epoch_Recall_7</td><td>0.0</td></tr><tr><td>train/epoch_Recall_8</td><td>0.0</td></tr><tr><td>train/epoch_TN_0</td><td>2045642.375</td></tr><tr><td>train/epoch_TN_1</td><td>2027233.875</td></tr><tr><td>train/epoch_TN_2</td><td>2097152.0</td></tr><tr><td>train/epoch_TN_3</td><td>2064854.25</td></tr><tr><td>train/epoch_TN_4</td><td>2069692.625</td></tr><tr><td>train/epoch_TN_5</td><td>2089360.375</td></tr><tr><td>train/epoch_TN_6</td><td>2091799.25</td></tr><tr><td>train/epoch_TN_7</td><td>2097152.0</td></tr><tr><td>train/epoch_TN_8</td><td>2097152.0</td></tr><tr><td>train/epoch_TP_0</td><td>37867.92578</td></tr><tr><td>train/epoch_TP_1</td><td>45987.75</td></tr><tr><td>train/epoch_TP_2</td><td>0.0</td></tr><tr><td>train/epoch_TP_3</td><td>19140.42578</td></tr><tr><td>train/epoch_TP_4</td><td>16638.84961</td></tr><tr><td>train/epoch_TP_5</td><td>4785.2627</td></tr><tr><td>train/epoch_TP_6</td><td>3794.1626</td></tr><tr><td>train/epoch_TP_7</td><td>0.0</td></tr><tr><td>train/epoch_TP_8</td><td>0.0</td></tr><tr><td>train/epoch_loss</td><td>0.75965</td></tr><tr><td>train/epoch_loss_build</td><td>0.48085</td></tr><tr><td>train/epoch_loss_speed</td><td>0.27879</td></tr><tr><td>train/iter_F1_0</td><td>0.78689</td></tr><tr><td>train/iter_F1_1</td><td>0.80324</td></tr><tr><td>train/iter_F1_2</td><td>0.0</td></tr><tr><td>train/iter_F1_3</td><td>0.74602</td></tr><tr><td>train/iter_F1_4</td><td>0.76083</td></tr><tr><td>train/iter_F1_5</td><td>0.82643</td></tr><tr><td>train/iter_F1_6</td><td>0.85413</td></tr><tr><td>train/iter_F1_7</td><td>0.0</td></tr><tr><td>train/iter_F1_8</td><td>0.0</td></tr><tr><td>train/iter_FN_0</td><td>2421.0</td></tr><tr><td>train/iter_FN_1</td><td>5072.0</td></tr><tr><td>train/iter_FN_2</td><td>0.0</td></tr><tr><td>train/iter_FN_3</td><td>2789.0</td></tr><tr><td>train/iter_FN_4</td><td>3085.0</td></tr><tr><td>train/iter_FN_5</td><td>305.0</td></tr><tr><td>train/iter_FN_6</td><td>321.0</td></tr><tr><td>train/iter_FN_7</td><td>0.0</td></tr><tr><td>train/iter_FN_8</td><td>0.0</td></tr><tr><td>train/iter_FP_0</td><td>21259.0</td></tr><tr><td>train/iter_FP_1</td><td>18363.0</td></tr><tr><td>train/iter_FP_2</td><td>0.0</td></tr><tr><td>train/iter_FP_3</td><td>7427.0</td></tr><tr><td>train/iter_FP_4</td><td>12125.0</td></tr><tr><td>train/iter_FP_5</td><td>1568.0</td></tr><tr><td>train/iter_FP_6</td><td>619.0</td></tr><tr><td>train/iter_FP_7</td><td>0.0</td></tr><tr><td>train/iter_FP_8</td><td>0.0</td></tr><tr><td>train/iter_IoU_0</td><td>0.64865</td></tr><tr><td>train/iter_IoU_1</td><td>0.67118</td></tr><tr><td>train/iter_IoU_2</td><td>0.0</td></tr><tr><td>train/iter_IoU_3</td><td>0.59492</td></tr><tr><td>train/iter_IoU_4</td><td>0.61398</td></tr><tr><td>train/iter_IoU_5</td><td>0.7042</td></tr><tr><td>train/iter_IoU_6</td><td>0.7454</td></tr><tr><td>train/iter_IoU_7</td><td>0.0</td></tr><tr><td>train/iter_IoU_8</td><td>0.0</td></tr><tr><td>train/iter_Precision_0</td><td>0.67282</td></tr><tr><td>train/iter_Precision_1</td><td>0.7226</td></tr><tr><td>train/iter_Precision_2</td><td>0.0</td></tr><tr><td>train/iter_Precision_3</td><td>0.6689</td></tr><tr><td>train/iter_Precision_4</td><td>0.66613</td></tr><tr><td>train/iter_Precision_5</td><td>0.73984</td></tr><tr><td>train/iter_Precision_6</td><td>0.81637</td></tr><tr><td>train/iter_Precision_7</td><td>0.0</td></tr><tr><td>train/iter_Precision_8</td><td>0.0</td></tr><tr><td>train/iter_Recall_0</td><td>0.94753</td></tr><tr><td>train/iter_Recall_1</td><td>0.90413</td></tr><tr><td>train/iter_Recall_2</td><td>0.0</td></tr><tr><td>train/iter_Recall_3</td><td>0.84325</td></tr><tr><td>train/iter_Recall_4</td><td>0.8869</td></tr><tr><td>train/iter_Recall_5</td><td>0.93598</td></tr><tr><td>train/iter_Recall_6</td><td>0.89554</td></tr><tr><td>train/iter_Recall_7</td><td>0.0</td></tr><tr><td>train/iter_Recall_8</td><td>0.0</td></tr><tr><td>train/iter_TN_0</td><td>2029754.0</td></tr><tr><td>train/iter_TN_1</td><td>2025882.0</td></tr><tr><td>train/iter_TN_2</td><td>2097152.0</td></tr><tr><td>train/iter_TN_3</td><td>2071932.0</td></tr><tr><td>train/iter_TN_4</td><td>2057750.0</td></tr><tr><td>train/iter_TN_5</td><td>2090820.0</td></tr><tr><td>train/iter_TN_6</td><td>2093460.0</td></tr><tr><td>train/iter_TN_7</td><td>2097152.0</td></tr><tr><td>train/iter_TN_8</td><td>2097152.0</td></tr><tr><td>train/iter_TP_0</td><td>43718.0</td></tr><tr><td>train/iter_TP_1</td><td>47835.0</td></tr><tr><td>train/iter_TP_2</td><td>0.0</td></tr><tr><td>train/iter_TP_3</td><td>15004.0</td></tr><tr><td>train/iter_TP_4</td><td>24192.0</td></tr><tr><td>train/iter_TP_5</td><td>4459.0</td></tr><tr><td>train/iter_TP_6</td><td>2752.0</td></tr><tr><td>train/iter_TP_7</td><td>0.0</td></tr><tr><td>train/iter_TP_8</td><td>0.0</td></tr><tr><td>train/iter_loss</td><td>0.78746</td></tr><tr><td>train/iter_loss_build</td><td>0.47984</td></tr><tr><td>train/iter_loss_speed</td><td>0.30762</td></tr><tr><td>train/mean_F1</td><td>0.47501</td></tr><tr><td>train/mean_IoU</td><td>0.392</td></tr><tr><td>trainer/global_step</td><td>7999</td></tr><tr><td>val/epoch_F1_0</td><td>0.77955</td></tr><tr><td>val/epoch_F1_1</td><td>0.68518</td></tr><tr><td>val/epoch_F1_2</td><td>0.0</td></tr><tr><td>val/epoch_F1_3</td><td>0.5031</td></tr><tr><td>val/epoch_F1_4</td><td>0.62472</td></tr><tr><td>val/epoch_F1_5</td><td>0.65331</td></tr><tr><td>val/epoch_F1_6</td><td>0.26374</td></tr><tr><td>val/epoch_F1_7</td><td>0.0</td></tr><tr><td>val/epoch_F1_8</td><td>0.0</td></tr><tr><td>val/epoch_FN_0</td><td>4277.14307</td></tr><tr><td>val/epoch_FN_1</td><td>7938.23828</td></tr><tr><td>val/epoch_FN_2</td><td>0.0</td></tr><tr><td>val/epoch_FN_3</td><td>6420.90479</td></tr><tr><td>val/epoch_FN_4</td><td>5147.28564</td></tr><tr><td>val/epoch_FN_5</td><td>782.7619</td></tr><tr><td>val/epoch_FN_6</td><td>129.2381</td></tr><tr><td>val/epoch_FN_7</td><td>0.0</td></tr><tr><td>val/epoch_FN_8</td><td>0.0</td></tr><tr><td>val/epoch_FP_0</td><td>14852.42871</td></tr><tr><td>val/epoch_FP_1</td><td>24781.66797</td></tr><tr><td>val/epoch_FP_2</td><td>0.0</td></tr><tr><td>val/epoch_FP_3</td><td>16000.47656</td></tr><tr><td>val/epoch_FP_4</td><td>11067.33398</td></tr><tr><td>val/epoch_FP_5</td><td>3065.52393</td></tr><tr><td>val/epoch_FP_6</td><td>1072.42859</td></tr><tr><td>val/epoch_FP_7</td><td>0.0</td></tr><tr><td>val/epoch_FP_8</td><td>0.0</td></tr><tr><td>val/epoch_IoU_0</td><td>0.64348</td></tr><tr><td>val/epoch_IoU_1</td><td>0.52452</td></tr><tr><td>val/epoch_IoU_2</td><td>0.0</td></tr><tr><td>val/epoch_IoU_3</td><td>0.34371</td></tr><tr><td>val/epoch_IoU_4</td><td>0.45902</td></tr><tr><td>val/epoch_IoU_5</td><td>0.52008</td></tr><tr><td>val/epoch_IoU_6</td><td>0.2199</td></tr><tr><td>val/epoch_IoU_7</td><td>0.0</td></tr><tr><td>val/epoch_IoU_8</td><td>0.0</td></tr><tr><td>val/epoch_Precision_0</td><td>0.69802</td></tr><tr><td>val/epoch_Precision_1</td><td>0.59466</td></tr><tr><td>val/epoch_Precision_2</td><td>0.0</td></tr><tr><td>val/epoch_Precision_3</td><td>0.43485</td></tr><tr><td>val/epoch_Precision_4</td><td>0.55552</td></tr><tr><td>val/epoch_Precision_5</td><td>0.57213</td></tr><tr><td>val/epoch_Precision_6</td><td>0.23044</td></tr><tr><td>val/epoch_Precision_7</td><td>0.0</td></tr><tr><td>val/epoch_Precision_8</td><td>0.0</td></tr><tr><td>val/epoch_Recall_0</td><td>0.8905</td></tr><tr><td>val/epoch_Recall_1</td><td>0.81447</td></tr><tr><td>val/epoch_Recall_2</td><td>0.0</td></tr><tr><td>val/epoch_Recall_3</td><td>0.65276</td></tr><tr><td>val/epoch_Recall_4</td><td>0.73314</td></tr><tr><td>val/epoch_Recall_5</td><td>0.79401</td></tr><tr><td>val/epoch_Recall_6</td><td>0.31138</td></tr><tr><td>val/epoch_Recall_7</td><td>0.0</td></tr><tr><td>val/epoch_Recall_8</td><td>0.0</td></tr><tr><td>val/epoch_TN_0</td><td>1956137.5</td></tr><tr><td>val/epoch_TN_1</td><td>1940527.5</td></tr><tr><td>val/epoch_TN_2</td><td>2009770.75</td></tr><tr><td>val/epoch_TN_3</td><td>1975960.375</td></tr><tr><td>val/epoch_TN_4</td><td>1979874.5</td></tr><tr><td>val/epoch_TN_5</td><td>2001156.375</td></tr><tr><td>val/epoch_TN_6</td><td>2006424.25</td></tr><tr><td>val/epoch_TN_7</td><td>2009770.75</td></tr><tr><td>val/epoch_TN_8</td><td>2009770.75</td></tr><tr><td>val/epoch_TP_0</td><td>34503.47656</td></tr><tr><td>val/epoch_TP_1</td><td>36523.33594</td></tr><tr><td>val/epoch_TP_2</td><td>0.0</td></tr><tr><td>val/epoch_TP_3</td><td>11388.95215</td></tr><tr><td>val/epoch_TP_4</td><td>13681.57129</td></tr><tr><td>val/epoch_TP_5</td><td>4766.04785</td></tr><tr><td>val/epoch_TP_6</td><td>2144.80957</td></tr><tr><td>val/epoch_TP_7</td><td>0.0</td></tr><tr><td>val/epoch_TP_8</td><td>0.0</td></tr><tr><td>val/epoch_loss</td><td>0.75222</td></tr><tr><td>val/epoch_loss_build</td><td>0.48543</td></tr><tr><td>val/epoch_loss_speed</td><td>0.26679</td></tr><tr><td>val/iter_F1_0</td><td>0.7749</td></tr><tr><td>val/iter_F1_1</td><td>0.68486</td></tr><tr><td>val/iter_F1_2</td><td>0.0</td></tr><tr><td>val/iter_F1_3</td><td>0.5111</td></tr><tr><td>val/iter_F1_4</td><td>0.62635</td></tr><tr><td>val/iter_F1_5</td><td>0.68172</td></tr><tr><td>val/iter_F1_6</td><td>0.27521</td></tr><tr><td>val/iter_F1_7</td><td>0.0</td></tr><tr><td>val/iter_F1_8</td><td>0.0</td></tr><tr><td>val/iter_FN_0</td><td>4438.9751</td></tr><tr><td>val/iter_FN_1</td><td>8194.50977</td></tr><tr><td>val/iter_FN_2</td><td>0.0</td></tr><tr><td>val/iter_FN_3</td><td>6561.90039</td></tr><tr><td>val/iter_FN_4</td><td>5354.81982</td></tr><tr><td>val/iter_FN_5</td><td>816.79504</td></tr><tr><td>val/iter_FN_6</td><td>134.85715</td></tr><tr><td>val/iter_FN_7</td><td>0.0</td></tr><tr><td>val/iter_FN_8</td><td>0.0</td></tr><tr><td>val/iter_FP_0</td><td>15406.53418</td></tr><tr><td>val/iter_FP_1</td><td>25756.04297</td></tr><tr><td>val/iter_FP_2</td><td>0.0</td></tr><tr><td>val/iter_FP_3</td><td>16679.58398</td></tr><tr><td>val/iter_FP_4</td><td>11403.91309</td></tr><tr><td>val/iter_FP_5</td><td>3198.41626</td></tr><tr><td>val/iter_FP_6</td><td>1119.05591</td></tr><tr><td>val/iter_FP_7</td><td>0.0</td></tr><tr><td>val/iter_FP_8</td><td>0.0</td></tr><tr><td>val/iter_IoU_0</td><td>0.63683</td></tr><tr><td>val/iter_IoU_1</td><td>0.52429</td></tr><tr><td>val/iter_IoU_2</td><td>0.0</td></tr><tr><td>val/iter_IoU_3</td><td>0.3504</td></tr><tr><td>val/iter_IoU_4</td><td>0.4609</td></tr><tr><td>val/iter_IoU_5</td><td>0.54269</td></tr><tr><td>val/iter_IoU_6</td><td>0.22946</td></tr><tr><td>val/iter_IoU_7</td><td>0.0</td></tr><tr><td>val/iter_IoU_8</td><td>0.0</td></tr><tr><td>val/iter_Precision_0</td><td>0.69221</td></tr><tr><td>val/iter_Precision_1</td><td>0.59107</td></tr><tr><td>val/iter_Precision_2</td><td>0.0</td></tr><tr><td>val/iter_Precision_3</td><td>0.42391</td></tr><tr><td>val/iter_Precision_4</td><td>0.56047</td></tr><tr><td>val/iter_Precision_5</td><td>0.59701</td></tr><tr><td>val/iter_Precision_6</td><td>0.24045</td></tr><tr><td>val/iter_Precision_7</td><td>0.0</td></tr><tr><td>val/iter_Precision_8</td><td>0.0</td></tr><tr><td>val/iter_Recall_0</td><td>0.88794</td></tr><tr><td>val/iter_Recall_1</td><td>0.81906</td></tr><tr><td>val/iter_Recall_2</td><td>0.0</td></tr><tr><td>val/iter_Recall_3</td><td>0.67211</td></tr><tr><td>val/iter_Recall_4</td><td>0.72695</td></tr><tr><td>val/iter_Recall_5</td><td>0.82854</td></tr><tr><td>val/iter_Recall_6</td><td>0.32492</td></tr><tr><td>val/iter_Recall_7</td><td>0.0</td></tr><tr><td>val/iter_Recall_8</td><td>0.0</td></tr><tr><td>val/iter_TN_0</td><td>2030358.25</td></tr><tr><td>val/iter_TN_1</td><td>2013908.625</td></tr><tr><td>val/iter_TN_2</td><td>2085754.375</td></tr><tr><td>val/iter_TN_3</td><td>2050665.125</td></tr><tr><td>val/iter_TN_4</td><td>2054833.875</td></tr><tr><td>val/iter_TN_5</td><td>2076766.25</td></tr><tr><td>val/iter_TN_6</td><td>2082262.625</td></tr><tr><td>val/iter_TN_7</td><td>2085754.375</td></tr><tr><td>val/iter_TN_8</td><td>2085754.375</td></tr><tr><td>val/iter_TP_0</td><td>35551.0625</td></tr><tr><td>val/iter_TP_1</td><td>37895.0</td></tr><tr><td>val/iter_TP_2</td><td>0.0</td></tr><tr><td>val/iter_TP_3</td><td>11847.86328</td></tr><tr><td>val/iter_TP_4</td><td>14161.94434</td></tr><tr><td>val/iter_TP_5</td><td>4973.26709</td></tr><tr><td>val/iter_TP_6</td><td>2238.06201</td></tr><tr><td>val/iter_TP_7</td><td>0.0</td></tr><tr><td>val/iter_TP_8</td><td>0.0</td></tr><tr><td>val/iter_loss</td><td>0.75683</td></tr><tr><td>val/iter_loss_build</td><td>0.48666</td></tr><tr><td>val/iter_loss_speed</td><td>0.27017</td></tr><tr><td>val/mean_F1</td><td>0.38996</td></tr><tr><td>val/mean_IoU</td><td>0.30119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">3090_fold0</strong>: <a href=\"https://wandb.ai/syuchimu/SpaceNet8_foundation/runs/sv6m3sa9\" target=\"_blank\">https://wandb.ai/syuchimu/SpaceNet8_foundation/runs/sv6m3sa9</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220727_115513-sv6m3sa9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(cfg.folds):\n",
    "    print(f'#'*60)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*60)\n",
    "    \n",
    "    # Setting   \n",
    "    cfg.fold = fold\n",
    "    wandb_logger = WandbLogger(\n",
    "        config=cfg,\n",
    "        name=f\"{cfg.runname}_fold{fold}\",\n",
    "        project=cfg.project,\n",
    "        group=cfg.group,\n",
    "        tags=[f'fold{fold}', '3090', 'notebook', 'foundation', 'build', 'speed'],\n",
    "        # entity='spaceshift',\n",
    "    )\n",
    "    \n",
    "    # Data\n",
    "    datamodule = SpaceNnet8Module(fold, cfg)\n",
    "    \n",
    "    # Model\n",
    "    model = SpaceNet8Model(cfg)\n",
    "    \n",
    "    # PATH\n",
    "    dirpath = f'{cfg.outdir}{cfg.group}/{cfg.runname}_fold-{fold}/'\n",
    "    filename = f\"best_fold-{fold}\"\n",
    "    best_model_path = dirpath + filename + \".ckpt\"\n",
    "\n",
    "\n",
    "    # Logging\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        dirpath=dirpath,\n",
    "        filename=filename,\n",
    "        monitor=\"val/mean_IoU\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "    )\n",
    "    wandb.save(cfg.notebook)\n",
    "    # logger = TensorBoardLogger()\n",
    "    \n",
    "    print(f'### Start Trainig')\n",
    "    # Train\n",
    "    trainer = Trainer(\n",
    "        logger=wandb_logger,\n",
    "        max_epochs=cfg.epoch,\n",
    "        callbacks=[lr_monitor, loss_checkpoint],\n",
    "        **cfg.trainer,\n",
    "    )\n",
    "    # 実行\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    # saving\n",
    "    with open(f'{dirpath}cfg.json', 'w') as f:\n",
    "        json.dump(cfg.to_dict(), f, indent=4)\n",
    "        \n",
    "    wandb.save(cfg.notebook)\n",
    "    wandb.finish()\n",
    "    break\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a6429481f04ab292af26e4eb5f9f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.100 MB of 1.100 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr-AdamW</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr-AdamW</td><td>0.001</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">3090_fold0</strong>: <a href=\"https://wandb.ai/syuchimu/SpaceNet8_foundation/runs/3kuqi441\" target=\"_blank\">https://wandb.ai/syuchimu/SpaceNet8_foundation/runs/3kuqi441</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220727_115338-3kuqi441/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f'[Error] {e} --> OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sn8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5035d61452180bc2f6c97d30efe0351efc32bce343eab0f718e68b06cec485d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
