{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet8 Multi Task Model\n",
    "\n",
    "1. flood\n",
    "2. foundation\n",
    "\n",
    "の両方を検証できる基盤を作成\n",
    "\n",
    "## overview\n",
    "- `data_prep` までは公開ベースラインと同じ\n",
    "- 学習部分のみの改善を試みる\n",
    "- pytorch lightning + wandb + SMP or TimmUNet の導入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "python-box\n",
    "tqdm\n",
    "timm\n",
    "ttach\n",
    "adabelief-pytorch\n",
    "albumentations\n",
    "segmentation-models-pytorch\n",
    "wandb\n",
    "tensorboard\n",
    "tensorboardX\n",
    "pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torch==1.8.0+cu111) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torch==1.8.0+cu111) (1.23.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/syu/anaconda3/envs/sn8/lib/python3.8/site-packages (from torchvision==0.9.0+cu111) (9.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.0\n",
      "    Uninstalling torchvision-0.13.0:\n",
      "      Successfully uninstalled torchvision-0.13.0\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -r ../docker/requirements.txt\n",
    "!pip install -q -r requirements.txt\n",
    "!conda install -y gdal\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyuchimu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/syu/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "from pprint import pprint\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "import glob\n",
    "import json\n",
    "import csv\n",
    "# import dataclasses\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from box import Box\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tifffile\n",
    "from osgeo import gdal\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from timm import create_model\n",
    "from adabelief_pytorch import AdaBelief\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import wandb\n",
    "wandb.login(key='****')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "pd.options.display.max_colwidth = 250\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# インライン表示\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATH_FOLD_CSV': '../../data/folds/',\n",
      " 'augmentation': '',\n",
      " 'debug': False,\n",
      " 'debug_sample': 32,\n",
      " 'epoch': 100,\n",
      " 'eps': 1e-12,\n",
      " 'f': 'flood',\n",
      " 'features': BoxList(['preimg', 'postimg', 'building', 'road', 'roadspeed', 'flood']),\n",
      " 'fold': -1,\n",
      " 'folds': 5,\n",
      " 'group': '3090_V4_FND+FLD_IMG512_multilabel',\n",
      " 'model': {'act': 'tanh',\n",
      "           'architecture': 'smp',\n",
      "           'decoder_channels': BoxList([256, 128, 64, 32, 16]),\n",
      "           'dropout_rato': 0.1,\n",
      "           'encoder_name': 'efficientnet-b0',\n",
      "           'in_channels': 6,\n",
      "           'loss': 'MultiBCEDiceLoss(raito=0.5)',\n",
      "           'loss_mode': 'multilabel',\n",
      "           'out_channels': 32,\n",
      "           'threshold': 0.4},\n",
      " 'notebook': 'multi_task.ipynb',\n",
      " 'optimizer': Box({'name': 'optim.AdamW', 'params': {'lr': 0.001}}),\n",
      " 'outdir': '../../train/output/syu/',\n",
      " 'preprocess': Box({'input_size': 512}),\n",
      " 'project': 'SpaceNet8',\n",
      " 'runname': '3090',\n",
      " 'scheduler': {'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
      "               'params': Box({'T_0': 20, 'eta_min': 1e-05})},\n",
      " 'seed': 417,\n",
      " 'train_loader': {'batch_size': 16,\n",
      "                  'drop_last': True,\n",
      "                  'num_workers': 8,\n",
      "                  'pin_memory': False,\n",
      "                  'shuffle': True},\n",
      " 'trainer': {'accumulate_grad_batches': 1,\n",
      "             'check_val_every_n_epoch': 2,\n",
      "             'fast_dev_run': False,\n",
      "             'gpus': 1,\n",
      "             'gradient_clip_algorithm': 'value',\n",
      "             'gradient_clip_val': 10.0,\n",
      "             'num_sanity_val_steps': 0,\n",
      "             'precision': 16,\n",
      "             'progress_bar_refresh_rate': 1,\n",
      "             'resume_from_checkpoint': None,\n",
      "             'stochastic_weight_avg': False,\n",
      "             'val_check_interval': 1.0},\n",
      " 'val_loader': {'batch_size': 16,\n",
      "                'drop_last': False,\n",
      "                'num_workers': 8,\n",
      "                'pin_memory': False,\n",
      "                'shuffle': False}}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Set, Dict, Any\n",
    "\n",
    "class CFG(object):\n",
    "    # basic\n",
    "    debug: bool = False\n",
    "    debug_sample: int = 32\n",
    "    folds: int  = 5\n",
    "    seed: int   = 417\n",
    "    eps: float  = 1e-12\n",
    "    outdir: str = '../../train/output/syu/'\n",
    "    \n",
    "    # data\n",
    "    PATH_FOLD_CSV: str  =  f'../../data/folds/'\n",
    "    \n",
    "    # train\n",
    "    epoch: int  = 100\n",
    "    trainer: Dict[str, Any]   = {\n",
    "        'gpus': 1,\n",
    "        'accumulate_grad_batches': 1,\n",
    "        'progress_bar_refresh_rate': 1,\n",
    "        'stochastic_weight_avg': False,\n",
    "        'fast_dev_run': False,\n",
    "        'num_sanity_val_steps': 0,\n",
    "        'resume_from_checkpoint': None,\n",
    "        'check_val_every_n_epoch': 2,\n",
    "        'val_check_interval': 1.0,\n",
    "        'precision' : 16,\n",
    "        'gradient_clip_val': 10., \n",
    "        'gradient_clip_algorithm': \"value\"\n",
    "    }\n",
    "    optimizer: Dict[str, Any] = {\n",
    "        'name': 'optim.AdamW',\n",
    "        'params': {\n",
    "            'lr': 1e-3,\n",
    "            },\n",
    "    }\n",
    "    scheduler: Dict[str, Any] = {\n",
    "        'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "        'params':{\n",
    "            'T_0': 20,\n",
    "            'eta_min': 1e-5,\n",
    "            }\n",
    "    }\n",
    "    model: Dict[str, Any] = {\n",
    "        \"architecture\": 'smp', # timmu, smp\n",
    "        \"threshold\": 0.4,\n",
    "        \n",
    "        'loss': 'MultiBCEDiceLoss(raito=0.5)',\n",
    "        # smp loss mode: https://smp.readthedocs.io/en/latest/_modules/segmentation_models_pytorch/losses/dice.html\n",
    "        'loss_mode': 'multilabel', # 'binary', 'multiclass' ,'multilabel'\n",
    "        \n",
    "        'in_channels': 0,\n",
    "        'out_channels': 32,\n",
    "        \n",
    "        # unet++ :https://smp.readthedocs.io/en/latest/_modules/segmentation_models_pytorch/decoders/unetplusplus/model.html\n",
    "        'decoder_channels': [int(256 / 2**i) for i in range(5)],\n",
    "        # 'decoder_channels': [256, 128, 64, 32, 32],\n",
    "        'encoder_name': 'efficientnet-b0',\n",
    "        'act': \"tanh\",\n",
    "        'dropout_rato': 0.1,\n",
    "    }\n",
    "    train_loader: Dict[str, Any] = {\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 8,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': True,\n",
    "    }\n",
    "    val_loader :Dict[str, Any]= {\n",
    "        'batch_size': 16,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 8,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': False\n",
    "    }\n",
    "    \n",
    "    # preprocess\n",
    "    features :List[str] = [\"preimg\",\"postimg\",\"building\",\"road\",\"roadspeed\",\"flood\"]\n",
    "    # [\"preimg\",\"postimg\",\"building\",\"road\",\"roadspeed\",\"flood\"]\n",
    "    \n",
    "    preprocess: Dict = {\n",
    "        \"input_size\": 512,\n",
    "    }\n",
    "    \n",
    "    # logging\n",
    "    project: str = \"SpaceNet8\"\n",
    "    runname: str = \"3090\"\n",
    "    group: str   = f'3090_V4_FND+FLD_IMG{preprocess[\"input_size\"]}_multilabel'\n",
    "    notebook: str = 'multi_task.ipynb'\n",
    "    \n",
    "    # post info\n",
    "    augmentation: str =  ''\n",
    "    fold: int = -1\n",
    "    \n",
    "    \n",
    "    # channels\n",
    "    for f in features:\n",
    "        if f == 'preimg':\n",
    "            model['in_channels'] += 3\n",
    "        elif f == 'postimg':\n",
    "            model['in_channels'] += 3\n",
    "\n",
    "        # if f == 'building':\n",
    "        #     model['out_channels'] += 1\n",
    "        # elif f == 'road':\n",
    "        #     model['out_channels']  += 1\n",
    "        # elif f == 'roadspeed':\n",
    "        #     model['out_channels']  += 8\n",
    "        # elif f == 'flood':\n",
    "        #     model['out_channels']  += 4\n",
    "        \n",
    "\n",
    "    if debug:\n",
    "        epoch = 2\n",
    "        group = 'DEBUG'\n",
    "\n",
    "\n",
    "# box\n",
    "cfg = Box({k:v for k, v in dict(vars(CFG)).items() if '__' not in k})\n",
    "    \n",
    "# 乱数のシードを設定\n",
    "seed_everything(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "random.seed(cfg.seed)\n",
    "    \n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'train':Compose([Transpose(always_apply=False,p=0.25),Flip(always_apply=False,p=0.5),Rotate(always_apply=False,p=0.5,limit=(-30,30),interpolation=1,border_mode=4,value=None,mask_value=None,method='largest_box',crop_border=False),Resize(always_apply=False,p=1,height=512,width=512,interpolation=1),ToTensorV2(always_apply=True,p=1.0,transpose_mask=False),],p=1.0,bbox_params=None,keypoint_params=None,additional_targets={}),'val':Compose([Resize(always_apply=False,p=1,height=512,width=512,interpolation=1),ToTensorV2(always_apply=True,p=1.0,transpose_mask=False),],p=1.0,bbox_params=None,keypoint_params=None,additional_targets={})}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# augmentation\n",
    "tf_dict = {\n",
    "    \n",
    "    'train': A.Compose(\n",
    "        [\n",
    "\n",
    "            # A.CoarseDropout(max_holes=4, max_height=4, max_width=4, \n",
    "            #                     min_holes=None, min_height=None, min_width=None, \n",
    "            #                     fill_value=0.15, mask_fill_value=0.0, always_apply=False, p=0.25),\n",
    "            # A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1,\n",
    "            #                     border_mode=4, value=None, mask_value=None, always_apply=False,\n",
    "            #                     approximate=False, same_dxdy=False, p=0.25),\n",
    "            # A.GridDistortion(num_steps=5, distort_limit=0.4, interpolation=1, \n",
    "            #                     border_mode=4, value=None, mask_value=None, always_apply=False, p=0.25),\n",
    "            # A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, interpolation=1, \n",
    "            #                     border_mode=4, value=0.01, mask_value=0.0, shift_limit_x=None, shift_limit_y=None, \n",
    "            #                     p=0.5),\n",
    "            # A.OneOf([\n",
    "            #     # A.GaussNoise(var_limit=(1e-3, 8e-1), mean=0.15, p=0.5),\n",
    "            #     A.Blur(blur_limit=9, p=0.25),\n",
    "            #     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, brightness_by_max=True, p=0.5),\n",
    "            # ], p=0.9),\n",
    "            A.Transpose(p=0.25),\n",
    "            A.Flip(p=0.5),\n",
    "            # A.HueSaturationValue (hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.5),\n",
    "            A.Rotate(limit=30, p=0.5),\n",
    "            A.Resize(cfg.preprocess.input_size, cfg.preprocess.input_size),\n",
    "    #         A.Normalize(mean=(0.485), std=(0.229)),\n",
    "            ToTensorV2(),\n",
    "            ]\n",
    "        ),\n",
    "    'val': A.Compose(\n",
    "        [\n",
    "            A.Resize(cfg.preprocess.input_size, cfg.preprocess.input_size),\n",
    "            # A.Normalize(mean=(0.485), std=(0.229)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "cfg.augmentation = str(tf_dict).replace('\\n', '').replace(' ', '')\n",
    "cfg.augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceNnet8Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 fold: int,\n",
    "                 phase: str,\n",
    "                 ):\n",
    "        \"\"\" pytorch dataset for spacenet-8 data. loads images from a csv that contains filepaths to the images\n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "        fold: (int) \n",
    "            preimg column contains filepaths to the pre-event image tiles (.tif)\n",
    "            postimg column contains filepaths to the post-event image tiles (.tif)\n",
    "            building column contains the filepaths to the binary building labels (.tif)\n",
    "            road column contains the filepaths to the binary road labels (.tif)\n",
    "            roadspeed column contains the filepaths to the road speed labels (.tif)\n",
    "            flood column contains the filepaths to the flood labels (.tif)\n",
    "        data_to_load (list): a list that defines which of the images and labels to load from the .csv. \n",
    "        \n",
    "        \"\"\"\n",
    "        self.all_data_types = [\"preimg\", \"postimg\", \"building\", \"road\", \"roadspeed\", \"flood\"]\n",
    "        \n",
    "        self.data_to_load = cfg.features\n",
    "        self.phase = phase\n",
    "        csv_filename = os.path.join(cfg.PATH_FOLD_CSV, f'fold{fold}_seed{cfg.seed}_{self.phase}.csv')\n",
    "        self.transform = tf_dict[self.phase]\n",
    "        \n",
    "        self.files = []\n",
    "\n",
    "        dict_template = {}\n",
    "        for i in self.all_data_types:\n",
    "            dict_template[i] = None\n",
    "        \n",
    "        with open(csv_filename, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for k, row in enumerate(reader):\n",
    "                in_data = copy.copy(dict_template)\n",
    "                for j in self.data_to_load:\n",
    "                    in_data[j]=row[j]\n",
    "                self.files.append(in_data)\n",
    "                \n",
    "                if cfg.debug and k > cfg.debug_sample:\n",
    "                    break\n",
    "        \n",
    "        print(\"loaded\", len(self.files), \"image filepaths\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_dict = self.files[index]\n",
    "\n",
    "        imgs, masks = [], []\n",
    "        \n",
    "        # gather\n",
    "        for i in self.all_data_types:\n",
    "            filepath = data_dict[i]\n",
    "            if filepath is not None:\n",
    "                # need to resample postimg to same spatial resolution/extent as preimg and labels.\n",
    "                if i == \"postimg\":\n",
    "                    ds = self.get_warped_ds(data_dict[\"postimg\"])\n",
    "                else:\n",
    "                    ds = gdal.Open(filepath)\n",
    "                image = ds.ReadAsArray()\n",
    "                ds = None\n",
    "            \n",
    "                if i in ['preimg' ,'postimg']:\n",
    "                    imgs.append(image.transpose(1, 2, 0))\n",
    "                else:\n",
    "                    # 1 channel\n",
    "                    if len(image.shape) <= 2:\n",
    "                        masks.append(image[:,:, np.newaxis])\n",
    "                    else:\n",
    "                        masks.append(image.transpose(1, 2, 0))\n",
    "                        \n",
    "                \n",
    "        \n",
    "        \n",
    "        # align channel last\n",
    "        imgs = np.concatenate(imgs, axis=2)\n",
    "        masks = np.concatenate(masks, axis=2)\n",
    "        \n",
    "        # augmentation\n",
    "        transformed = self.transform(image=imgs, mask=masks)\n",
    "        \n",
    "        imgs = transformed[\"image\"]\n",
    "        masks = transformed[\"mask\"].permute(2, 0, 1) # torch channel fast\n",
    "        \n",
    "        return imgs, masks\n",
    "\n",
    "    def get_image_filename(self, index: int) -> str:\n",
    "        \"\"\" return pre-event image absolute filepath at index \"\"\"\n",
    "        data_dict = self.files[index]\n",
    "        return data_dict[\"preimg\"]\n",
    "\n",
    "    def get_warped_ds(self, post_image_filename: str) -> gdal.Dataset:\n",
    "        \"\"\" gdal warps (resamples) the post-event image to the same spatial resolution as the pre-event image and masks \n",
    "        \n",
    "        SN8 labels are created from referencing pre-event image. Spatial resolution of the post-event image does not match the spatial resolution of the pre-event imagery and therefore the labels.\n",
    "        In order to align the post-event image with the pre-event image and mask labels, we must resample the post-event image to the resolution of the pre-event image. Also need to make sure\n",
    "        the post-event image covers the exact same spatial extent as the pre-event image. this is taken care of in the the tiling\"\"\"\n",
    "        ds = gdal.Warp(\"\", post_image_filename,\n",
    "                       format='MEM', width=1300, height=1300,\n",
    "                       resampleAlg=gdal.GRIORA_Bilinear,\n",
    "                       outputType=gdal.GDT_Byte)\n",
    "        return ds\n",
    "    \n",
    "class SpaceNnet8Module(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fold,\n",
    "        cfg,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fold = fold\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = SpaceNnet8Dataset(self.fold, phase='train')\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = SpaceNnet8Dataset(self.fold, phase='val')\n",
    "        return DataLoader(dataset, **self._cfg.val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(smp.utils.base.Loss):\n",
    "    \"\"\"DiceLoss which supports ignore mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=cfg.eps, beta=0.5, ignore_mask_channel=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.beta = beta\n",
    "        self.ignore_mask_channel = ignore_mask_channel\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        # y_pr, y_gt = _apply_ignore_mask(y_pr, y_gt, self.ignore_mask_channel)\n",
    "\n",
    "        return 1 - smp.utils.functional.f_score(\n",
    "            y_pr,\n",
    "            y_gt,\n",
    "            beta=self.beta,\n",
    "            eps=self.eps,\n",
    "            threshold=None,\n",
    "            ignore_channels=None,\n",
    "        )\n",
    "\n",
    "class BCEDiceLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.dice_criterion = DiceLoss()\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss = self.raito * self.bce_criterion(y_pr, y_gt) + (1 - self.raito) * self.dice_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        return loss\n",
    "    \n",
    "class MultiBCEDiceLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(MultiBCEDiceLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.dice_criterion = smp.losses.DiceLoss(mode=cfg.model.loss_mode)\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss_bce = self.raito * self.bce_criterion(y_pr, y_gt)\n",
    "\n",
    "        if cfg.model.loss_mode == 'multiclass':\n",
    "            y_gt = y_gt.long()\n",
    "            y_gt = torch.argmax(y_gt, dim=1)\n",
    "        loss_dice = (1 - self.raito) * self.dice_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        \n",
    "        loss = loss_bce + loss_dice\n",
    "        return loss\n",
    "\n",
    "class MultiBCETverskyLoss(torch.nn.Module):\n",
    "    def __init__(self, raito=0.5):\n",
    "        super(MultiBCETverskyLoss, self).__init__()\n",
    "        assert 0 <= raito <= 1, \"loss raito invalid.\"\n",
    "        \n",
    "        self.raito = raito\n",
    "        self.bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.tvrsky_criterion = smp.losses.TverskyLoss(mode=cfg.model.loss_mode, log_loss=False)\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        loss_bce = self.raito * self.bce_criterion(y_pr, y_gt)\n",
    "\n",
    "        if cfg.model.loss_mode == 'multiclass':\n",
    "            y_gt = y_gt.long()\n",
    "            y_gt = torch.argmax(y_gt, dim=1)\n",
    "        loss_dice = (1 - self.raito) * self.tvrsky_criterion(torch.sigmoid(y_pr), y_gt)\n",
    "        \n",
    "        loss = loss_bce + loss_dice\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam\n",
    "\n",
    "\n",
    "class SpaceNet8Model(LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(cfg.model.loss)\n",
    "        \n",
    "    def __build_model(self):\n",
    "        self.backbone = smp.UnetPlusPlus(encoder_name=cfg.model.encoder_name,\n",
    "                                              encoder_weights=\"imagenet\",\n",
    "                                      decoder_attention_type='scse',\n",
    "                                      in_channels=cfg.model.in_channels, activation=cfg.model.act,\n",
    "                                      decoder_channels=cfg.model.decoder_channels,\n",
    "                                      classes=cfg.model.out_channels)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(cfg.model.dropout_rato, inplace=False)\n",
    "        self.proj_build = nn.Conv2d(cfg.model.out_channels, 1, (1, 1), stride=1, padding=0, dilation=1, groups=1,)\n",
    "        self.proj_road = nn.Conv2d(cfg.model.out_channels, 1, (1, 1), stride=1, padding=0, dilation=1, groups=1,)\n",
    "        self.proj_speed = nn.Conv2d(cfg.model.out_channels, 8, (1, 1), stride=1, padding=0, dilation=1, groups=1,)\n",
    "        self.proj_flood = nn.Conv2d(cfg.model.out_channels, 4, (1, 1), stride=1, padding=0, dilation=1, groups=1,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.dropout(self.backbone(x))\n",
    "        \n",
    "        # multi task split\n",
    "        build = self.proj_build(feat)\n",
    "        road = self.proj_road(feat)\n",
    "        speed = self.proj_speed(feat)\n",
    "        flood = self.proj_flood(feat)\n",
    "        \n",
    "        return build, road, speed, flood\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.__share_step(batch, 'train')\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.__share_step(batch, 'val')\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, labels = batch\n",
    "        labels = labels.float()\n",
    "        images = images.float()\n",
    "\n",
    "        build, road, speed, flood = self.forward(images)\n",
    "\n",
    "        # loss\n",
    "        loss_build = self._criterion(build, labels[:, 0,...].unsqueeze(dim=1))\n",
    "        loss_road = self._criterion(road, labels[:, 1,...].unsqueeze(dim=1))\n",
    "        loss_speed = self._criterion(speed, labels[:, 1:9,...])\n",
    "        loss_flood = self._criterion(flood, labels[:, 10:14,...])\n",
    "        # sum\n",
    "        loss = loss_build + loss_road + loss_speed + loss_flood\n",
    "        \n",
    "        logits = torch.sigmoid(torch.cat([build, road, speed, flood], dim=1))\n",
    "        preds = (logits > cfg.model.threshold).float()\n",
    "        return_dict = {'loss': loss , \n",
    "                       'loss_build': loss_build, 'loss_road': loss_road, \n",
    "                       'loss_speed': loss_speed, 'loss_flood': loss_flood}\n",
    "        \n",
    "        # metrics\n",
    "        for c in range(14):\n",
    "            preds_c, labels_c = preds[:, c, :, :], labels[:, c, :, :]\n",
    "            tp = (preds_c * labels_c).sum().to(torch.float32)\n",
    "            tn = ((1. - preds_c) * (1. - labels_c)).sum().to(torch.float32)\n",
    "            fp = (preds_c * (1. - labels_c)).sum().to(torch.float32)\n",
    "            fn = ((1. - preds_c) * labels_c).sum().to(torch.float32)\n",
    "            return_dict[f'TP_{c}'] = tp.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'TN_{c}'] = tn.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'FP_{c}'] = fp.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'FN_{c}'] = fn.unsqueeze(dim=0).detach().cpu()\n",
    "            \n",
    "            precision = tp / (tp + fp + cfg.eps)\n",
    "            recall = tp / (tp + fn + cfg.eps)\n",
    "            f1 = 2 * (precision*recall) / (precision + recall + cfg.eps)\n",
    "            iou = tp / (tp + fp + fn + cfg.eps)\n",
    "            \n",
    "            return_dict[f'Precision_{c}'] = precision.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'Recall_{c}'] = recall.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'F1_{c}'] = f1.unsqueeze(dim=0).detach().cpu()\n",
    "            return_dict[f'IoU_{c}'] = iou.unsqueeze(dim=0).detach().cpu()\n",
    "            \n",
    "            # logging \n",
    "            self.log(f'{mode}/iter_TP_{c}', tp)\n",
    "            self.log(f'{mode}/iter_TN_{c}', tn)\n",
    "            self.log(f'{mode}/iter_FP_{c}', fp)\n",
    "            self.log(f'{mode}/iter_FN_{c}', fn)\n",
    "            \n",
    "            self.log(f'{mode}/iter_Precision_{c}', precision)\n",
    "            self.log(f'{mode}/iter_Recall_{c}', recall)\n",
    "            \n",
    "            self.log(f'{mode}/iter_F1_{c}', f1)\n",
    "            self.log(f'{mode}/iter_IoU_{c}', iou) \n",
    "            \n",
    "        self.log(f'{mode}/iter_loss', loss)\n",
    "        for target in ['build', 'road', 'speed', 'flood']:\n",
    "            self.log(f'{mode}/iter_loss_{target}', eval(f'loss_{target}'))\n",
    "\n",
    "        return return_dict\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.__share_epoch_end(outputs, 'train')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.__share_epoch_end(outputs, 'val')    \n",
    "        \n",
    "    def __share_epoch_end(self, outputs, mode):\n",
    "        \n",
    "        # loss\n",
    "        losses = []\n",
    "        for target in ['build', 'road', 'speed', 'flood']:\n",
    "            exec(f'losses_{target} = []')\n",
    "            \n",
    "        for out in outputs:\n",
    "            losses.append(out['loss'].cpu().detach().numpy())\n",
    "        losses = np.mean(losses)\n",
    "        self.log(f'{mode}/epoch_loss', losses)\n",
    "        \n",
    "        for target in ['build', 'road', 'speed', 'flood']:\n",
    "            for out in outputs:\n",
    "                exec(f\"losses_{target}.append(out[f'loss_{target}'].cpu().detach().numpy())\")\n",
    "            exec(f'losses_{target} = np.mean(losses_{target})')\n",
    "            exec(f'self.log(f\"{mode}/epoch_loss_{target}\", losses_{target})')\n",
    "        \n",
    "        mean_iou = 0\n",
    "        mean_f1 = 0\n",
    "    \n",
    "        # metrics\n",
    "        for c in range(14):\n",
    "            tps, tns, fps, fns, precisions, recalls, f1s, IoUs = \\\n",
    "                [], [], [], [], [], [], [], []\n",
    "            for out in outputs:\n",
    "                # assert False, (out[f'TP_{c}'], out[f'TP_{c}'].shape)\n",
    "                for (tp, tn, fp, fn, precision, recall, f1, iou) in zip(out[f'TP_{c}'], \n",
    "                                         out[f'TN_{c}'],\n",
    "                                         out[f'FP_{c}'],\n",
    "                                         out[f'FN_{c}'],\n",
    "                                         out[f'Precision_{c}'],\n",
    "                                         out[f'Recall_{c}'],\n",
    "                                         out[f'F1_{c}'],\n",
    "                                         out[f'IoU_{c}'],):\n",
    "                    \n",
    "                    tps.append(tp.unsqueeze(dim=0))\n",
    "                    tns.append(tn.unsqueeze(dim=0))\n",
    "                    fps.append(fp.unsqueeze(dim=0))\n",
    "                    fns.append(fn.unsqueeze(dim=0))\n",
    "                    \n",
    "                    precisions.append(precision.unsqueeze(dim=0))\n",
    "                    recalls.append(recall.unsqueeze(dim=0))\n",
    "                    f1s.append(f1.unsqueeze(dim=0))\n",
    "                    IoUs.append(iou.unsqueeze(dim=0))\n",
    "                    \n",
    "            tps = torch.cat(tps, dim=0).squeeze()\n",
    "            tns = torch.cat(tns, dim=0).squeeze()\n",
    "            fps = torch.cat(fps, dim=0).squeeze()\n",
    "            fns = torch.cat(fns, dim=0).squeeze()\n",
    "            \n",
    "            precisions = torch.cat(precisions, dim=0).squeeze()\n",
    "            recalls = torch.cat(recalls, dim=0).squeeze()\n",
    "            f1s = torch.cat(f1s, dim=0).squeeze()\n",
    "            IoUs = torch.cat(IoUs, dim=0).squeeze()\n",
    "            \n",
    "            \n",
    "            # logging \n",
    "            self.log(f'{mode}/epoch_TP_{c}', tps)\n",
    "            self.log(f'{mode}/epoch_TN_{c}', tns)\n",
    "            self.log(f'{mode}/epoch_FP_{c}', fps)\n",
    "            self.log(f'{mode}/epoch_FN_{c}', fns)\n",
    "            \n",
    "            self.log(f'{mode}/epoch_Precision_{c}', precisions)\n",
    "            self.log(f'{mode}/epoch_Recall_{c}', recalls)\n",
    "            \n",
    "            self.log(f'{mode}/epoch_F1_{c}', f1s)\n",
    "            self.log(f'{mode}/epoch_IoU_{c}', IoUs)\n",
    "            \n",
    "            mean_iou += np.mean(IoUs.numpy()).item()\n",
    "            mean_f1 += np.mean(f1s.numpy()).item()\n",
    "        \n",
    "        mean_iou /= 14\n",
    "        mean_f1 /= 14\n",
    "        self.log(f'{mode}/mean_IoU', mean_iou)\n",
    "        self.log(f'{mode}/mean_F1', mean_f1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "        scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **self.cfg.scheduler.params\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "### Fold: 0\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/syu/c983cccd-1cc7-4ce4-b206-7eb1a2cc5c94/topcoder/spacenet8/SpaceNet8/baseline/wandb/run-20220724_010929-1lro960a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/syuchimu/SpaceNet8/runs/1lro960a\" target=\"_blank\">3090_fold0</a></strong> to <a href=\"https://wandb.ai/syuchimu/SpaceNet8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start Trainig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | backbone   | UnetPlusPlus     | 6.6 M \n",
      "1 | dropout    | Dropout2d        | 0     \n",
      "2 | proj_build | Conv2d           | 33    \n",
      "3 | proj_road  | Conv2d           | 33    \n",
      "4 | proj_speed | Conv2d           | 264   \n",
      "5 | proj_flood | Conv2d           | 132   \n",
      "6 | _criterion | MultiBCEDiceLoss | 0     \n",
      "------------------------------------------------\n",
      "6.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 M     Total params\n",
      "13.292    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 640 image filepaths\n",
      "loaded 161 image filepaths\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a9190aee944b8f93f81c0297fc334d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e30200e6a7d440c925845847de45e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d57e5b1a30409280c084c586a9b97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f040f4e4404f17862671b441559650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7319258488d04c11a2a4cb248cc5cd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb80ce516c95446b93a64cf57d0202ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdcc71fb6284acba2514c0d898efd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b682e1662a34797a63643a172933ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47660aa01fe4bbd9f823fc8e3f82eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be752158d93243469314f66efac67a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a141aea0e247a3bfc853be179cb9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3305991ccf4ded80fbf6e8a15b19d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4936476ccdeb4751a4f2eb1a93ba4171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bdcc33e5d343439799c4aa0995ac95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c799cc862949e3a64b5ba340e1baa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c7633351144e889c2428f95af5b25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36b17a5f2bc4b0b8ed3527c069c540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f686ba755b48df9bf2e38dd9008e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e0508cb0754bb787607ed8577224b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b578b2a61e438cb46886d03363cedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3328d7f3464c119d28484fa89494c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdfaeb9b5624379bfd15332dd2080ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f198f4696d2b42d4b62078c91fe118e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d81964de595451e95a4507e4c437fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15d484e679a4c338de73d05ce37daaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69d1af8d3b649048ecc56a0ce7a87a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd8eaad90454defbd31256a0f4db623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b5049217584a069114559433fa6702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16c35c345074dd19d73f085b6b7ec25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c88150aa1604357a443f26af549a8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dfb2b80e5c40b49e14be043b0822f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b8410ee1cf455b9174a56ed9f314bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952b551ba61d427d9687fd66e5dbeb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46b1f86cba741bfa2a3c058f9b2c02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92915883f7da43078fa8e42cdb78e13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976f847c505047fa96ac2b77bb2fbbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ba0f7c0ee348c5bd6aa250a16afc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58655c5091b54dcb85a8874a7c349142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d692178dedc4c9f8e9f002e0e284cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3cc8441eac49fe80f2668abd17bf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f19f02137864b05a316a44870b52212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77f27122bc34109ae68662c9b86353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33ff96ad57f4d0b8398a4d425575bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03a38d9b21c4d32a23c484c32922e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1f20efe78443ce876c99ade805bfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef22767e19ef4dcf91a19c15d67dff4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154f3f5271bc4546b92c2de0af188a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319714c3c49141d2b032dab740978daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8560d6f7c644be88d761a8938993e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc8ee2603254d1e9c4498b59b9fba2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd49c01c33345f686975ce916d68248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fcaad888f64e51b179d9394ac02987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.063 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.011682…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-AdamW</td><td>██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁██▇▆▄▃▂▁</td></tr><tr><td>train/epoch_F1_0</td><td>▁▁▁▁▇▇▇▇▇▇▇▇▇█████▇██████▇███████▇██████</td></tr><tr><td>train/epoch_F1_1</td><td>▁▁▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇██████▇██████</td></tr><tr><td>train/epoch_F1_10</td><td>▁▁▁▁▂▃▅▆▆▆▇▇▇▇██▇▇▇█▇████▇███████▇██████</td></tr><tr><td>train/epoch_F1_11</td><td>▄▁▂▁▁▁▁▃▁▁▂▁▂▁▁█▁▁▁▂▁▁▁▁▃▁▂▁▃▁▂▂█▁▁▁▁▂▁▃</td></tr><tr><td>train/epoch_F1_12</td><td>▁▁▁▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇▇▇██████▇██████</td></tr><tr><td>train/epoch_F1_13</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▄▄▂▃▁▁▅▂▃▄▇▂▃▄▃▃▆▆█▅▄</td></tr><tr><td>train/epoch_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_3</td><td>█▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_4</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▅▅▅▆▆▆▆▇▇█▇▇▇▇▇▇████▇▇▇█▇███</td></tr><tr><td>train/epoch_F1_5</td><td>▁▁▁▁▂▂▄▄▄▅▄▅▆▇▇▇▇▇▇▇▇█▇▇████▇▇▇▇▇▇█▇█▇▇▇</td></tr><tr><td>train/epoch_F1_6</td><td>▂▁▁▁▁▁▁▃▁▁▁▁▁▃▁▁▇▁▁▁▁▂▂▂▂▂▄▁█▄▁▁▁▄▂▂▁▁▄▁</td></tr><tr><td>train/epoch_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_F1_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_0</td><td>▆███▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_1</td><td>▆██▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_10</td><td>▅████▇▅▅▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_11</td><td>▁█████▇██▇█████▇███████████▇███▇█▇██████</td></tr><tr><td>train/epoch_FN_12</td><td>▂███▇▆▅▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_13</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_3</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_FN_4</td><td>▁█████████▇▇▆▅▅▅▄▄▄▃▂▂▂▂▃▃▃▂▁▂▁▂▂▃▂▂▂▁▁▁</td></tr><tr><td>train/epoch_FN_5</td><td>▁█████▇▇▇▇▇▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▄▄▃▃▃▄▃▄</td></tr><tr><td>train/epoch_FN_6</td><td>▁▇▇██▇█▇▇▇███▇▇████▇██▇▇█▇▇▇▇██▇██▇▇▇▇██</td></tr><tr><td>train/epoch_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FN_9</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_FP_0</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_1</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_10</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_11</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_12</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_13</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_2</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train/epoch_FP_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_4</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_5</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_6</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_8</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_FP_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_0</td><td>▁▁▁▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇█████▇██████</td></tr><tr><td>train/epoch_IoU_1</td><td>▁▁▁▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train/epoch_IoU_10</td><td>▁▁▁▁▁▃▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇████▇▇▇█████▇██████</td></tr><tr><td>train/epoch_IoU_11</td><td>▃▁▂▁▁▁▁▃▁▁▂▁▁▁▁█▁▁▁▂▁▁▁▁▂▁▂▁▃▁▁▁▇▁▁▁▁▂▁▃</td></tr><tr><td>train/epoch_IoU_12</td><td>▁▁▁▁▂▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train/epoch_IoU_13</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▄▄▂▃▁▁▅▂▃▄▇▂▃▄▂▃▆▆█▅▄</td></tr><tr><td>train/epoch_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_3</td><td>█▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_4</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▅▆▆▆▇▇█▇▇▇▇▇▇█▇██▇▇▇█▇███</td></tr><tr><td>train/epoch_IoU_5</td><td>▁▁▁▁▂▂▃▄▄▅▄▅▆▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>train/epoch_IoU_6</td><td>▂▁▁▁▁▁▁▃▁▁▁▁▁▃▁▁▇▁▁▁▁▂▂▂▂▂▄▁█▄▁▁▁▄▂▂▁▁▄▁</td></tr><tr><td>train/epoch_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_IoU_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_0</td><td>▁▁▄█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████▇▇▇█████▇██████</td></tr><tr><td>train/epoch_Precision_1</td><td>▁▁▅▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█████▇▇██████▇██████</td></tr><tr><td>train/epoch_Precision_10</td><td>▁▁▃▁▅▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train/epoch_Precision_11</td><td>▁▂▄▁▁▁▃▃▁▁▄▁▂▁▁▃▁▁▃▂▆▅▂▃▆▅▄▄▅▃▅▃▅▂▆▁▂▅█▇</td></tr><tr><td>train/epoch_Precision_12</td><td>▁▁▂▂▇████▇▇▇▇▇▇█▇▇▇▇█████▇███████▇██████</td></tr><tr><td>train/epoch_Precision_13</td><td>▁▂▂▁▁▁▁▁▁▁▂▁▁▂▂▂▃▂▂▃▂▅▃▁▂▅▃▃▅█▂▄▆▄▇▆▆▇▄▆</td></tr><tr><td>train/epoch_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_3</td><td>▄▁▄▁▁▁▁▁▁▁█▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁</td></tr><tr><td>train/epoch_Precision_4</td><td>▁▂▂▁▁▁▁▂▂▃▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_Precision_5</td><td>▁▂▄▁▄▅█▅▇▇▅▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▆▆▅▅▅▅▅▆▆▅▅▅▅▅</td></tr><tr><td>train/epoch_Precision_6</td><td>▁▁▄▁▁▁▁▂▁▁▁▁▁▄▁▁▃▁▁▂▁▆▃▄▂▃▄▁▇▂▁▂▁▄█▁▁▁▃▄</td></tr><tr><td>train/epoch_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Precision_9</td><td>▂▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_0</td><td>▃▁▁▁▇▇▇▇▇▇▇▇██████▇██████▇██████████████</td></tr><tr><td>train/epoch_Recall_1</td><td>▃▁▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇███▇▇▇██████▇██████</td></tr><tr><td>train/epoch_Recall_10</td><td>▄▁▁▁▁▂▄▄▅▅▇▇▇▇▇▇▇▇▇▇█████▇██████████████</td></tr><tr><td>train/epoch_Recall_11</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_12</td><td>▆▁▁▁▂▃▄▄▄▅▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████▇▇██████</td></tr><tr><td>train/epoch_Recall_13</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_4</td><td>█▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▅▅▅▆▇▇▇▇▆▆▆▇█▇██▇▆▇▇▇███</td></tr><tr><td>train/epoch_Recall_5</td><td>█▁▁▁▁▁▂▂▂▃▂▂▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▅▆▅▅▅▆▆▆▅▆▅</td></tr><tr><td>train/epoch_Recall_6</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_Recall_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TN_0</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_1</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_10</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_11</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_12</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_13</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_2</td><td>▁████████████████▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_TN_3</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_4</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_5</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_6</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_7</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TN_9</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/epoch_TP_0</td><td>▃▁▁▁▇▇▇▇▇▇▇▇██████▇██████▇██████████████</td></tr><tr><td>train/epoch_TP_1</td><td>▃▁▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇█████▇██████</td></tr><tr><td>train/epoch_TP_10</td><td>▄▁▁▁▁▂▄▄▅▅▇▇▇▇▇▇▇▇▇██████▇▇█████████████</td></tr><tr><td>train/epoch_TP_11</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_12</td><td>▇▁▁▁▂▃▄▄▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇██████</td></tr><tr><td>train/epoch_TP_13</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_4</td><td>█▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▄▅▅▆▇▇▇▇▆▆▆▆█▇█▇▇▆▇▇▇███</td></tr><tr><td>train/epoch_TP_5</td><td>█▁▁▁▁▁▂▂▂▂▂▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▅▅▆▆▆▅▆▅</td></tr><tr><td>train/epoch_TP_6</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_TP_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_build</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_flood</td><td>█▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_road</td><td>█▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_speed</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_0</td><td>▁▁▁▇▇▇▇▇▇▆▆██▆█▇▅▇▄██▇██▇▆▆▇█▇▇▆▇▆▇▇█▇▇█</td></tr><tr><td>train/iter_F1_1</td><td>▁▁▂▆▇▇▇▇▆▆▆█▇▇▇▇▆▇▇████▇█▆▇█████▇▇██████</td></tr><tr><td>train/iter_F1_10</td><td>▁▁▁▁▂▂▆▂▆▅▅█▇▄▇▄▄▇▃█▇▇█▇▆▅▆▇▇▇▇▅▆▆▇▇█▇▇▇</td></tr><tr><td>train/iter_F1_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>train/iter_F1_12</td><td>▁▁▁▃▂▆▄▅▆▆▇▇▇▇▇▅▅▇▆██▇▇▇▇▆█████▆▆▇▇█▇▇█▇</td></tr><tr><td>train/iter_F1_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁█▁▁</td></tr><tr><td>train/iter_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_4</td><td>▁▁▁▁▁▁▁▂▁▁▄▂▂▃▂▄▅▅▃█▅█▆▇▇▄▅▇▇▆▇▅▆▅▅▅▄▄▇▆</td></tr><tr><td>train/iter_F1_5</td><td>▁▁▁▁▁▄▄▂▄▇▄▃▃▂▄▆▁▃▆▁▄▂▃▃▅▄█▆▃▃▃▄▄▅▄▆▁▄▄▅</td></tr><tr><td>train/iter_F1_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_F1_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_0</td><td>▅▆█▃▂▂▃▂▁▁▁▃▃▁▁▂▁▁▁▂▂▂▂▁▁▂▁▂▂▂▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train/iter_FN_1</td><td>▇██▃▃▂▄▂▂▂▂▂▃▂▁▂▁▁▁▂▁▂▂▂▁▁▂▁▁▁▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>train/iter_FN_10</td><td>▆▅█▇▇▆▆▂▂▂▂▄▄▁▁▁▁▁▁▂▂▂▃▁▁▁▂▃▂▂▁▂▂▂▃▂▂▂▂▂</td></tr><tr><td>train/iter_FN_11</td><td>▁▃▃▁▁▁▂▆▄▂▃▃▁▂▂█▂▁▂▁▃▄▁▅▂▃▁▂▂▁▂▅▃▁▂▂▂▁▂▅</td></tr><tr><td>train/iter_FN_12</td><td>▇▇█▆▇▄▇▂▃▃▂▂▄▃▁▁▁▂▁▃▁▂▂▂▁▁▂▂▂▂▂▁▁▂▂▂▂▁▁▁</td></tr><tr><td>train/iter_FN_13</td><td>▂▃▃▂▃▁▃▆▂▃▃▃▂▂▃█▂▂▃▁▂▅▄▄▃▃▁▂▃▁▄▇▆▂▄▃▃▃▂▄</td></tr><tr><td>train/iter_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_3</td><td>▇█▄▅▆▄▇▄▄▅▄▃▅▅▄▆▁▃▂▆▅▆▇▇▃▃▄▂▅▅▄▆▁▂▅▆▃▆▅▃</td></tr><tr><td>train/iter_FN_4</td><td>▃▄▅▄▆▃█▄▃▂▃▇▇▄▁▃▁▂▂▄▂▅▂▂▂▂▂▃▃▂▄▃▅▃▃▃▆▂▂▃</td></tr><tr><td>train/iter_FN_5</td><td>▂▅▅▄▁▅▄█▇▃▄▄▄▅▄▄▃▄▅▁▃▃▃▅▄▂▃▃▃▁▇▄▃▂▄▆▂▂▃▂</td></tr><tr><td>train/iter_FN_6</td><td>▅▃█▃▃▂▂▂▃▁▁▁▁▁▃▁▂▂▃▁▂▁▅▂▂▂▁▂▁▃▂▁▁▂▄▂▃▁▁▃</td></tr><tr><td>train/iter_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FN_9</td><td>▆▆▇▅▆▄█▅▅▃▄▆▆▄▃▅▁▃▂▆▄█▆▆▄▃▃▄▅▅▆▅▄▃▆▆▅▄▄▅</td></tr><tr><td>train/iter_FP_0</td><td>▁▁▁▂▇▄▄▅█▄▆▄▃▃▂▆▃▂▇▄▂█▄▆▃▆▄▃▃▅▆▄▅▅▂▆▆▃▄▄</td></tr><tr><td>train/iter_FP_1</td><td>▁▂▁▄▆▅▄▆▇▄▆▄▄▄▅▆▆▅▄▅▅▆▅▇▅█▄▄▄▄▅▄▅▅▃▄▆▅▄▅</td></tr><tr><td>train/iter_FP_10</td><td>▁▁▁▁▂▁▂▄▅▂▄▃▂▃▂█▃▂▅▃▃▇▃▆▃▅▂▂▃▄▅▄▄▄▂▄▄▂▃▅</td></tr><tr><td>train/iter_FP_11</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅</td></tr><tr><td>train/iter_FP_12</td><td>▁▁▁▁▁▂▂▆▄▃▄▄▃▃▄█▅▄▄▃▄▆▅▆▅▇▃▃▄▃▅▇▆▄▄▄▆▅▄▅</td></tr><tr><td>train/iter_FP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▃▁▁▄▃▁▁▁▂▁▁▁▁▂▁▂▁</td></tr><tr><td>train/iter_FP_2</td><td>▁▁▁▂▄▄▄▅▆▄▅▆▅▅▅▆▄▅▄▇▆█▇▇▆▇▅▅▆▆▇▆▆▅▆▇▇▆▆▆</td></tr><tr><td>train/iter_FP_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▁▂▄▄▂▅▄▃▇▆██▇▆▆▄▅▆▅▇▃▅▅▆▅█▆▇</td></tr><tr><td>train/iter_FP_5</td><td>▁▁▁▁▁▂▁▂▃▁▃▄▂▃▃▅▂▅▃▅▆█▆█▅▅▄▄▅▅▆▆▄▄▅▄▅▆▆▇</td></tr><tr><td>train/iter_FP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train/iter_FP_7</td><td>▁▁▁▁▁▁▁█▃▁▃▂▁▁▂▁▁▂▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_8</td><td>▁▁▁▁█▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_FP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_0</td><td>▁▁▁▆▆▇▇▆▆▅▅█▇▅▇▇▄▇▃██▇█▇▇▅▅▇█▇▇▆▆▆▇▇▇▆▇█</td></tr><tr><td>train/iter_IoU_1</td><td>▁▁▁▆▆▆▆▆▆▅▆█▇▆▇▇▅▇▆▇▇▇█▇▇▅▇████▇▇▇██▇███</td></tr><tr><td>train/iter_IoU_10</td><td>▁▁▁▁▂▂▅▁▅▄▄▇▇▄▇▃▃▇▃█▇▆█▆▅▄▆▇▇▇▇▄▅▅▇▆▇▆▇▆</td></tr><tr><td>train/iter_IoU_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>train/iter_IoU_12</td><td>▁▁▁▂▂▅▃▄▅▅▆▆▆▆▇▄▄▇▅█▇▆▇▆▇▅▇█▇█▇▅▅▇▇█▇▆█▇</td></tr><tr><td>train/iter_IoU_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁█▁▁</td></tr><tr><td>train/iter_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_4</td><td>▁▁▁▁▁▁▁▁▁▁▄▂▁▃▂▄▅▄▂█▄█▅▆▆▃▄▇▇▅▇▄▅▄▅▄▄▄▇▆</td></tr><tr><td>train/iter_IoU_5</td><td>▁▁▁▁▁▃▄▂▄▇▃▂▃▂▄▅▁▃▆▁▄▂▂▃▄▄█▆▃▃▃▄▃▄▃▆▁▄▄▄</td></tr><tr><td>train/iter_IoU_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_IoU_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_0</td><td>▁█▁▇▆▇▇▆▅▅▅██▅▇▆▄▇▃▇█▆█▆▇▅▅▇▇▇▆▆▆▆█▆▇▆▆▇</td></tr><tr><td>train/iter_Precision_1</td><td>▁▂█▇▇▆▇▆▆▆▆▇▇▇▇▇▅▆▆▇▇▇█▇▇▅▇▇▇▇█▇▇▆██▇▇▇▇</td></tr><tr><td>train/iter_Precision_10</td><td>▁▁▁▁▆▇█▂▅▅▄██▄▆▃▃▇▂▇▇▅█▅▅▄▆▇▇▇▆▄▅▆▇▆▇▆▆▆</td></tr><tr><td>train/iter_Precision_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>train/iter_Precision_12</td><td>▁▁▁▇███▄▆▆▆▆▇▇▆▄▄▆▅█▇▆▇▆▆▄▇▇▇█▇▄▅▆▇▇▆▅▇▆</td></tr><tr><td>train/iter_Precision_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁█▁▁</td></tr><tr><td>train/iter_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_4</td><td>▁▁▁▁▁▁▁█▁▁▇▃█▅▂▄▅▄▂█▃▇▄▅▄▃▃▆▆▄▆▄▇▄▄▄▄▃▅▄</td></tr><tr><td>train/iter_Precision_5</td><td>▁▁▁▁▁▂█▂▂▅▂▂▂▂▂▃▁▂▃▁▂▁▁▂▂▂▃▃▂▂▂▂▂▂▂▃▁▂▂▂</td></tr><tr><td>train/iter_Precision_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Precision_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_0</td><td>▁▁▁▅▇▇▇▇█▆▇▇▇▆█▇▆▇▆█▇▇██▇▇▇▇▇██▆▇▇▇▇█▇▇▇</td></tr><tr><td>train/iter_Recall_1</td><td>▁▁▁▅▆▇▆▇▇▆▆▇▆▆█▇▇▇▇▇█▇███▇▇████▇▇▇▇█████</td></tr><tr><td>train/iter_Recall_10</td><td>▁▁▁▁▂▂▅▂▇▅▅▇▆▅▇▇▅▇▆▇▇▇▇█▆▆▆▆▇▇█▅▆▆▆▇▇▆▇▇</td></tr><tr><td>train/iter_Recall_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>train/iter_Recall_12</td><td>▁▁▁▂▂▄▃▅▅▅▆▆▅▆▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████</td></tr><tr><td>train/iter_Recall_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁█▁▁</td></tr><tr><td>train/iter_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_4</td><td>▁▁▁▁▁▁▁▁▁▁▃▁▁▂▃▄▄▅▃▆▆▇▇██▅▅▆▇▆▆▅▄▅▄▅▃▆▇▇</td></tr><tr><td>train/iter_Recall_5</td><td>▁▁▁▁▁▃▂▂▃▄▃▃▂▂▃▆▁▃▄▅▇▄▅▄▅▆█▇▄█▃▅▅▆▄▅▂▇▆█</td></tr><tr><td>train/iter_Recall_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_Recall_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TN_0</td><td>▆▆▄▅▃▅▂▅▄▇▆▁▃▇█▄█▇▇▄▆▂▃▄▇▆▇▅▅▄▅▅▅▆▅▄▃▇▅▃</td></tr><tr><td>train/iter_TN_1</td><td>▆▅▄▅▂▆▁▄▃▇▅▄▄▅▇▃█▆█▄▆▁▃▂▆▄▇▆▅▅▃▄▅▆▄▃▃▆▆▅</td></tr><tr><td>train/iter_TN_10</td><td>▅▆▄▅▄▅▂▇▅█▆▁▃▇█▅█▇▇▄▆▂▂▄▇▆▇▅▄▄▄▆▅▅▅▄▂▇▅▃</td></tr><tr><td>train/iter_TN_11</td><td>█▆▆███▇▃▅▇▆▆█▇▇▁▇█▇█▆▅█▄▇▆█▇▇█▇▄▆█▇▇▇█▇▄</td></tr><tr><td>train/iter_TN_12</td><td>▆▆▅▆▆▇▃▆▄█▆▄▃▅▇▅█▆▇▃▅▁▃▂▆▅▆▆▅▅▃▅▆▆▅▃▃▆▅▅</td></tr><tr><td>train/iter_TN_13</td><td>▇▆▆▇▆█▆▃▇▆▆▆▇▇▇▁▇▇▆█▆▄▅▅▆▆█▇▆█▅▂▃▇▅▆▆▅▇▅</td></tr><tr><td>train/iter_TN_2</td><td>███▇▅▅▅▄▃▅▄▃▄▄▄▃▅▄▅▂▃▁▂▂▃▂▄▄▃▃▂▃▃▄▃▂▂▃▃▃</td></tr><tr><td>train/iter_TN_3</td><td>▂▁▅▄▃▅▂▅▅▄▅▆▄▄▅▃█▆▇▃▄▃▂▂▆▆▅▇▄▄▅▃█▇▄▃▆▃▄▆</td></tr><tr><td>train/iter_TN_4</td><td>█▇▆▇▅█▄▇▇█▇▄▅▆█▅█▆▇▃▅▁▃▃▄▅▆▅▄▄▃▄▃▅▅▄▃▄▄▃</td></tr><tr><td>train/iter_TN_5</td><td>█▇▇▇█▆▇▅▄▇▅▅▆▅▅▃▇▄▅▅▃▂▃▁▃▄▄▄▄▄▂▂▅▅▃▃▅▃▃▂</td></tr><tr><td>train/iter_TN_6</td><td>▄▆▁▆▆▇▇▇▆█████▆█▇▇▆█▇█▄▇▇▇█▇█▆▇██▇▅▇▆██▆</td></tr><tr><td>train/iter_TN_7</td><td>███████▁▆█▆▇██▇██▇██▄███████████████████</td></tr><tr><td>train/iter_TN_8</td><td>████▁█████▆█████████████████████████████</td></tr><tr><td>train/iter_TN_9</td><td>▃▃▂▄▃▅▁▄▄▆▅▃▃▅▆▄█▆▇▃▅▁▃▃▅▆▆▅▄▄▃▄▅▆▃▃▄▅▅▄</td></tr><tr><td>train/iter_TP_0</td><td>▁▁▁▄▆▄▇▃▄▂▃█▆▂▂▄▁▂▂▅▄▆▇▅▃▃▂▄▅▅▄▃▄▃▄▅▆▃▄▆</td></tr><tr><td>train/iter_TP_1</td><td>▁▁▁▅▆▅▆▅▅▄▅▇▆▅▅▆▃▅▄▇▆██▇▆▅▅▅▆▆▇▆▅▅▇▇▇▆▆▆</td></tr><tr><td>train/iter_TP_10</td><td>▁▁▁▁▂▁▅▁▃▂▂█▆▂▂▂▁▃▂▆▄▆█▄▂▂▃▄▅▆▄▂▃▃▄▅▇▃▄▅</td></tr><tr><td>train/iter_TP_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>train/iter_TP_12</td><td>▁▁▁▂▂▄▃▃▅▃▅▆▆▅▅▄▃▆▄█▆██▇▅▄▆▆▇▇▇▄▄▅▆█▇▅▇▆</td></tr><tr><td>train/iter_TP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁█▁▁</td></tr><tr><td>train/iter_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_4</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▂▃▁▆▃█▄▅▄▂▂▄▅▄▅▃▄▃▃▃▃▃▄▅</td></tr><tr><td>train/iter_TP_5</td><td>▁▁▁▁▁▂▂▂▄▃▃▂▂▂▃▆▁▃▄▁▄▃▃▄▅▄█▆▃▃▃▅▃▄▄▇▁▄▅▆</td></tr><tr><td>train/iter_TP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_TP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/iter_loss</td><td>█▅▅▄▄▄▄▄▄▄▃▂▃▃▄▃▄▄▄▂▄▃▃▄▄▄▁▄▃▃▃▃▃▄▃▃▃▃▃▃</td></tr><tr><td>train/iter_loss_build</td><td>█▆▅▄▃▃▂▄▃▄▄▁▂▄▄▃▄▄▅▂▃▂▁▂▄▄▄▃▂▂▃▄▃▄▃▃▂▄▃▂</td></tr><tr><td>train/iter_loss_flood</td><td>█▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>train/iter_loss_road</td><td>█▆▄▃▃▃▃▃▃▃▃▂▂▃▂▂▃▂▃▂▂▁▁▂▂▃▂▂▂▂▁▂▂▂▁▁▂▂▂▁</td></tr><tr><td>train/iter_loss_speed</td><td>█▅▄▄▄▄▄▄▄▄▁▁▁▁▄▁▄▄▄▁▄▄▄▄▄▄▁▄▄▄▄▁▁▄▄▄▄▁▁▄</td></tr><tr><td>train/mean_F1</td><td>▁▁▁▂▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████▇███████▇██████</td></tr><tr><td>train/mean_IoU</td><td>▁▁▁▂▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇███▇▇▇▇█████▇██████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/epoch_F1_0</td><td>▁▁▁▁▇▇▇█▇▇▇██████████████▇██████████████</td></tr><tr><td>val/epoch_F1_1</td><td>▁▁▁▆▇▇▇▇▇▇▇▇████▇████████▇██████████████</td></tr><tr><td>val/epoch_F1_10</td><td>▁▁▁▁▁▆▇▆▆▇▇█████▇██▇████████████████████</td></tr><tr><td>val/epoch_F1_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_12</td><td>▁▁▁▁▃▅▆▆▆▇▇▇████▇▇███████▇██████████████</td></tr><tr><td>val/epoch_F1_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆▅▄▆▇▇▇▇▇▇▇▇▆█████▇▇██▇███</td></tr><tr><td>val/epoch_F1_5</td><td>▁▁▁▁▁▁▁▁▁▁▂▅▆▇▇▇▅▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/epoch_F1_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_F1_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_0</td><td>████▁▁▁▂▃▂▃▂▂▁▁▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_1</td><td>███▃▂▂▂▂▃▂▃▂▂▂▁▂▂▂▁▂▂▁▁▁▂▃▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_10</td><td>█████▄▄▄▄▃▄▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▁▂▁▁▁▂</td></tr><tr><td>val/epoch_FN_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_12</td><td>████▇▅▄▄▄▂▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▃▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_4</td><td>████████████▇▆▅▅▆▄▃▄▃▂▃▂▃▄▄▂▁▁▂▂▂▃▁▂▂▂▂▂</td></tr><tr><td>val/epoch_FN_5</td><td>███████████▆▅▄▃▃▆▃▃▃▃▂▂▂▃▃▃▂▂▁▁▂▃▃▁▂▂▂▂▂</td></tr><tr><td>val/epoch_FN_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FN_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_0</td><td>▁▁▁▁█▇▇▅▃▅▃▆▅▆▆▅▅▄▅▃▄▄▅▅▅▆▅▆▆▄▅▅▄▄▇▅▅▅▅▄</td></tr><tr><td>val/epoch_FP_1</td><td>▁▁▁▅▇▆▇▆▅█▅▅▆▆▇▆▅▇█▅▆▆▆▆▆▄▅▇▇▆▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>val/epoch_FP_10</td><td>▁▁▁▁▁▂▃▂▂▄▂▅▅▆▇▅▅▄▆▃▅▄▅▆▆▇▅▇▆▅▆▅▅▅█▅▅▆▅▅</td></tr><tr><td>val/epoch_FP_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_12</td><td>▁▁▁▁▁▂▃▃▃▆▅▅▆▆▇▆▅▇█▆▆▆▆▆▆▅▅██▇▇▇▇▇█▇▇▇▇▆</td></tr><tr><td>val/epoch_FP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_2</td><td>▁▁▁▁▅▅▅▅▄▇▆▆▇▇▇▇▆▇█▇▇▇▇▇▇▆▇██▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>val/epoch_FP_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▅▅▅▅▆▆▆▅▄▅▇█▇▇▇▆▆█▇▇▇▇▇</td></tr><tr><td>val/epoch_FP_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▄▃▅▅▄▅▅▅▆▅▄▄▇▇▇▇▇▅▅█▆▇▆▆▆</td></tr><tr><td>val/epoch_FP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_FP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_0</td><td>▁▁▁▁▇▇▇▇▇▇▇▇██▇█▇██▇█████▇████████▇█████</td></tr><tr><td>val/epoch_IoU_1</td><td>▁▁▁▆▇▇▇▇▇▇▇▇▇███▇▇▇██████▇██████▇▇██████</td></tr><tr><td>val/epoch_IoU_10</td><td>▁▁▁▁▁▆▆▆▅▆▆▇▇███▇▇▇▇█████▇██████████████</td></tr><tr><td>val/epoch_IoU_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_12</td><td>▁▁▁▁▃▅▆▆▅▇▆▇▇▇█▇▇▇▇▇████▇▇▇█████▇▇██████</td></tr><tr><td>val/epoch_IoU_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▄▅▅▄▅▇▆▇▇▇▇▇▆▆█████▇▇█▇▇▇▇█</td></tr><tr><td>val/epoch_IoU_5</td><td>▁▁▁▁▁▁▁▁▁▁▂▄▆▆▇▇▅▆▇▇▇▇▇▇▇██▇▆▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val/epoch_IoU_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_IoU_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_0</td><td>▁▇▃▄▆▇▇▇█▇█▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇█▇▇██▇█▇▇▇█</td></tr><tr><td>val/epoch_Precision_1</td><td>▁▂▅█▇▇▇██▇██▇█▇██▇▇████████▇▇███▇▇▇▇▇███</td></tr><tr><td>val/epoch_Precision_10</td><td>▁▁▁▁▁█▇██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val/epoch_Precision_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_12</td><td>▁▁▁▁██▇█▇▆▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▆▆▇▇▇▆▆▆▆▆▇▇▇</td></tr><tr><td>val/epoch_Precision_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁█▇▇▆▇▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>val/epoch_Precision_5</td><td>▁▁▁▁▁▁▁▁▁▁▄▆▆▆▆▇▆▆▆▆▆▆▆▆▆█▇▆▅▆▆▆▆▆▅▆▆▆▆▆</td></tr><tr><td>val/epoch_Precision_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Precision_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_0</td><td>▁▁▁▁███▇▆▇▆▇▇███▇▇▇▇▇▇▇█▇▇▇█████▇▇██████</td></tr><tr><td>val/epoch_Recall_1</td><td>▁▁▁▅▇▇▇▇▆▇▆▇▇▇█▇▇▇█▇▇███▇▆▇█████▇▇██████</td></tr><tr><td>val/epoch_Recall_10</td><td>▁▁▁▁▁▅▅▅▄▆▅▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇█▇▇██▇</td></tr><tr><td>val/epoch_Recall_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_12</td><td>▁▁▁▁▂▄▅▅▄▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇█████▇▇██████</td></tr><tr><td>val/epoch_Recall_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▃▅▆▅▆▆▆▇▆▅▅▇█▇▇▇▆▆█▇▇▇▇▇</td></tr><tr><td>val/epoch_Recall_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▅▆▆▃▆▆▆▆▇▇▇▆▆▆▇███▇▆▆███▇▇▇</td></tr><tr><td>val/epoch_Recall_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_Recall_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_0</td><td>████▁▂▂▄▆▄▆▃▄▃▃▄▄▅▄▆▅▅▄▄▄▃▄▃▃▅▄▄▅▅▂▄▄▄▄▅</td></tr><tr><td>val/epoch_TN_1</td><td>███▄▂▃▂▃▄▁▄▄▃▃▂▃▄▂▁▄▃▃▃▃▃▅▄▂▂▃▃▃▂▃▂▃▃▃▃▃</td></tr><tr><td>val/epoch_TN_10</td><td>█████▇▆▇▇▅▇▄▄▃▂▄▄▅▃▆▄▅▄▃▃▂▄▂▃▄▃▄▄▄▁▄▄▃▄▄</td></tr><tr><td>val/epoch_TN_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_12</td><td>█████▇▆▆▆▃▄▄▃▃▂▃▄▂▁▃▃▃▃▃▃▄▄▁▁▂▂▂▂▂▁▂▂▂▂▃</td></tr><tr><td>val/epoch_TN_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_2</td><td>████▄▄▄▄▅▂▃▃▂▂▂▂▃▂▁▂▂▂▂▂▂▃▂▁▁▂▂▂▂▂▁▂▂▂▂▂</td></tr><tr><td>val/epoch_TN_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_4</td><td>████████████▇▇▆▆▆▄▄▄▄▃▃▃▄▅▄▂▁▂▂▂▃▃▁▂▂▂▂▂</td></tr><tr><td>val/epoch_TN_5</td><td>███████████▆▅▅▄▅▆▄▄▅▄▄▄▃▄▅▅▂▂▂▂▂▄▄▁▃▂▃▃▃</td></tr><tr><td>val/epoch_TN_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TN_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_0</td><td>▁▁▁▁███▇▆▇▆▇▇██▇▇▇▇▇▇▇▇█▇▇▇█████▇▇██████</td></tr><tr><td>val/epoch_TP_1</td><td>▁▁▁▆▇▇▇▇▆▇▆▇▇▇█▇▇▇█▇▇███▇▆▇█████▇▇██████</td></tr><tr><td>val/epoch_TP_10</td><td>▁▁▁▁▁▅▅▅▅▆▅▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇█▇███▇</td></tr><tr><td>val/epoch_TP_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_12</td><td>▁▁▁▁▂▄▅▅▅▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇█████▇▇██████</td></tr><tr><td>val/epoch_TP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▃▅▆▅▆▇▆▇▆▅▅▇██▇▇▇▆█▇▇▇▇▇</td></tr><tr><td>val/epoch_TP_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▅▆▆▃▆▆▆▆▇▇▇▆▆▆▇▇██▇▆▆█▇▇▇▇▇</td></tr><tr><td>val/epoch_TP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_TP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss_build</td><td>█▅▅▄▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss_flood</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss_road</td><td>█▅▄▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val/epoch_loss_speed</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_0</td><td>▁▁▁▁▇▇▇█▇▇▇██████████████▇██████████████</td></tr><tr><td>val/iter_F1_1</td><td>▁▁▁▇▇▇▇▇▇▇▇▇██████▇██████▇██████████████</td></tr><tr><td>val/iter_F1_10</td><td>▁▁▁▁▁▆▇▆▆▇▇█████▇██▇████████████████████</td></tr><tr><td>val/iter_F1_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_12</td><td>▁▁▁▁▃▆▆▆▆▇▇▇████▇████████▇██████████████</td></tr><tr><td>val/iter_F1_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆▅▅▆▇▇▇█▇█▇▇▆█████▇▇██▇███</td></tr><tr><td>val/iter_F1_5</td><td>▁▁▁▁▁▁▁▁▁▁▂▅▆▇▇▇▅▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val/iter_F1_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_F1_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_0</td><td>████▁▁▁▂▃▂▃▂▂▁▁▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_1</td><td>███▃▂▂▂▂▃▂▃▂▂▂▁▂▂▂▁▂▂▁▁▁▂▃▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_10</td><td>█████▄▄▄▄▃▄▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▁▂▁▁▁▂</td></tr><tr><td>val/iter_FN_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_12</td><td>████▇▅▄▄▄▂▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▃▂▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_4</td><td>████████████▇▆▅▅▆▄▃▄▃▂▃▂▃▄▄▂▁▁▂▂▂▃▁▂▂▂▂▂</td></tr><tr><td>val/iter_FN_5</td><td>███████████▆▅▄▃▃▆▃▃▃▃▂▂▂▃▃▃▂▂▁▁▂▃▃▁▂▂▂▂▂</td></tr><tr><td>val/iter_FN_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FN_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_0</td><td>▁▁▁▁█▇▇▅▃▅▃▆▅▆▆▅▅▄▅▃▄▄▅▅▅▆▅▆▆▄▅▅▄▄▇▅▅▅▅▄</td></tr><tr><td>val/iter_FP_1</td><td>▁▁▁▅▇▆▇▆▅█▅▅▆▆▇▆▅▇█▅▆▆▆▆▆▄▅▇▇▆▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>val/iter_FP_10</td><td>▁▁▁▁▁▂▃▂▂▄▂▅▅▆▇▅▅▄▆▃▅▄▅▆▆▇▅▇▆▅▆▅▅▅█▅▅▆▅▅</td></tr><tr><td>val/iter_FP_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_12</td><td>▁▁▁▁▁▂▃▃▃▇▅▅▆▆▇▆▅▇█▆▆▆▆▆▆▅▅██▇▇▇▇▇█▇▇▇▇▆</td></tr><tr><td>val/iter_FP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_2</td><td>▁▁▁▁▅▅▅▅▄▇▆▆▇▇▇▇▆▇█▇▇▇▇▇▇▆▇██▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>val/iter_FP_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▅▅▅▅▆▆▆▅▄▅▇█▇▇▇▆▆█▇▇▇▇▇</td></tr><tr><td>val/iter_FP_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▄▃▅▅▄▅▅▅▆▅▄▄▇▇▇▇▇▅▅█▆▇▆▆▆</td></tr><tr><td>val/iter_FP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_FP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_0</td><td>▁▁▁▁▇▇▇▇▇▇▇▇████▇██▇█████▇████████▇█████</td></tr><tr><td>val/iter_IoU_1</td><td>▁▁▁▆▇▇▇▇▇▇▇▇████▇▇▇██████▇██████▇███████</td></tr><tr><td>val/iter_IoU_10</td><td>▁▁▁▁▁▆▆▆▅▆▆▇▇███▇▇▇▇█████▇███████▇██████</td></tr><tr><td>val/iter_IoU_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_12</td><td>▁▁▁▁▃▅▆▆▅▇▆▇▇███▇▇▇▇████▇▇▇█████▇▇██████</td></tr><tr><td>val/iter_IoU_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆▅▄▆▇▇▇▇▇█▇▆▆█████▇▇██▇█▇█</td></tr><tr><td>val/iter_IoU_5</td><td>▁▁▁▁▁▁▁▁▁▁▂▄▆▆▇▇▅▆▇▇▇▇▇▇▇██▇▆▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val/iter_IoU_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_IoU_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_0</td><td>▁▇▄▅▆▇▇▇█▇█▇▇▇▇▇▇█▇███▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇</td></tr><tr><td>val/iter_Precision_1</td><td>▁▂▆█▇▇▇██▇████▇██▇▇████████▇▇███▇█▇█████</td></tr><tr><td>val/iter_Precision_10</td><td>▁▁▁▁▁█▇██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val/iter_Precision_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_12</td><td>▁▁▁▁██▇▇▇▆▇▇▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▆▆▇▆▇▆▆▆▆▆▇▇▇</td></tr><tr><td>val/iter_Precision_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁█▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>val/iter_Precision_5</td><td>▁▁▁▁▁▁▁▁▁▁▄▆▆▆▆▇▆▆▆▆▆▆▆▆▆█▇▆▅▆▆▆▆▆▅▆▆▆▆▆</td></tr><tr><td>val/iter_Precision_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Precision_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_0</td><td>▁▁▁▁███▇▆▇▆▇▇██▇▇▇▇▇▇▇▇█▇▇▇█████▇▇██████</td></tr><tr><td>val/iter_Recall_1</td><td>▁▁▁▆▇▇▇▇▆▇▆▇▇▇█▇▇▇█▇▇███▇▆▇█████▇▇██████</td></tr><tr><td>val/iter_Recall_10</td><td>▁▁▁▁▁▅▅▅▄▆▅▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇█▇▇█▇▇</td></tr><tr><td>val/iter_Recall_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_12</td><td>▁▁▁▁▂▄▅▅▅▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇█████▇▇██████</td></tr><tr><td>val/iter_Recall_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▃▅▆▅▆▇▆▇▆▅▅▇██▇▇▇▆█▇▇▇▇▇</td></tr><tr><td>val/iter_Recall_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▅▆▆▃▆▆▆▆▇▇▇▆▆▆▇███▇▆▆███▇▇▇</td></tr><tr><td>val/iter_Recall_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_Recall_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_0</td><td>████▁▂▂▄▆▄▆▃▄▃▃▄▄▅▄▆▅▅▄▄▄▃▄▃▃▅▄▄▅▅▂▄▄▄▄▅</td></tr><tr><td>val/iter_TN_1</td><td>███▄▂▃▂▃▄▁▄▄▃▃▂▃▄▂▁▄▃▃▃▃▃▅▄▂▂▃▃▃▂▃▂▃▃▃▃▃</td></tr><tr><td>val/iter_TN_10</td><td>█████▇▆▇▇▅▇▄▄▃▂▄▄▅▃▆▄▅▄▃▃▂▄▂▃▄▃▄▄▄▁▄▄▃▄▄</td></tr><tr><td>val/iter_TN_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_12</td><td>█████▇▆▆▆▂▄▄▃▃▂▃▄▂▁▃▃▃▃▃▃▄▄▁▁▂▂▂▂▂▁▂▂▂▂▃</td></tr><tr><td>val/iter_TN_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_2</td><td>████▄▄▄▄▅▂▃▃▂▂▂▂▃▂▁▂▂▂▂▂▂▃▂▁▁▂▂▂▂▂▁▂▂▂▂▂</td></tr><tr><td>val/iter_TN_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_4</td><td>████████████▇▇▆▆▆▄▄▄▄▃▃▃▄▅▄▂▁▂▂▂▃▃▁▂▂▂▂▂</td></tr><tr><td>val/iter_TN_5</td><td>███████████▆▅▅▄▅▆▄▄▅▄▄▄▃▄▅▅▂▂▂▂▂▄▄▁▃▂▃▃▃</td></tr><tr><td>val/iter_TN_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TN_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_0</td><td>▁▁▁▁███▇▆▇▆▇▇██▇▇▇▇▇▇▇▇█▇▇▇█████▇▇██████</td></tr><tr><td>val/iter_TP_1</td><td>▁▁▁▆▇▇▇▇▆▇▆▇▇▇█▇▇▇█▇▇███▇▆▇█████▇▇██████</td></tr><tr><td>val/iter_TP_10</td><td>▁▁▁▁▁▅▅▅▅▆▅▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇█▇███▇</td></tr><tr><td>val/iter_TP_11</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_12</td><td>▁▁▁▁▂▄▅▅▅▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇█████▇▇██████</td></tr><tr><td>val/iter_TP_13</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▃▅▆▅▆▇▆▇▆▅▅▇██▇▇▇▆█▇▇▇▇▇</td></tr><tr><td>val/iter_TP_5</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▅▆▆▃▆▆▆▆▇▇▇▆▆▆▇▇██▇▆▆█▇▇▇▇▇</td></tr><tr><td>val/iter_TP_6</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_7</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_8</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_TP_9</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss_build</td><td>█▅▅▄▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss_flood</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss_road</td><td>█▅▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/iter_loss_speed</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mean_F1</td><td>▁▁▁▂▄▆▆▆▆▆▆▇▇▇█▇▇▇███████▇██████████████</td></tr><tr><td>val/mean_IoU</td><td>▁▁▁▂▄▅▆▆▅▆▆▇▇▇▇▇▇▇▇▇█████▇▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-AdamW</td><td>2e-05</td></tr><tr><td>train/epoch_F1_0</td><td>0.80428</td></tr><tr><td>train/epoch_F1_1</td><td>0.79473</td></tr><tr><td>train/epoch_F1_10</td><td>0.72229</td></tr><tr><td>train/epoch_F1_11</td><td>0.00364</td></tr><tr><td>train/epoch_F1_12</td><td>0.7195</td></tr><tr><td>train/epoch_F1_13</td><td>0.01297</td></tr><tr><td>train/epoch_F1_2</td><td>0.0</td></tr><tr><td>train/epoch_F1_3</td><td>0.0</td></tr><tr><td>train/epoch_F1_4</td><td>0.36502</td></tr><tr><td>train/epoch_F1_5</td><td>0.17756</td></tr><tr><td>train/epoch_F1_6</td><td>4e-05</td></tr><tr><td>train/epoch_F1_7</td><td>0.0</td></tr><tr><td>train/epoch_F1_8</td><td>0.0</td></tr><tr><td>train/epoch_F1_9</td><td>0.0</td></tr><tr><td>train/epoch_FN_0</td><td>12374.02539</td></tr><tr><td>train/epoch_FN_1</td><td>15007.5498</td></tr><tr><td>train/epoch_FN_10</td><td>13077.40039</td></tr><tr><td>train/epoch_FN_11</td><td>13138.40039</td></tr><tr><td>train/epoch_FN_12</td><td>15964.7998</td></tr><tr><td>train/epoch_FN_13</td><td>17290.0</td></tr><tr><td>train/epoch_FN_2</td><td>0.0</td></tr><tr><td>train/epoch_FN_3</td><td>42986.85156</td></tr><tr><td>train/epoch_FN_4</td><td>20559.05078</td></tr><tr><td>train/epoch_FN_5</td><td>6229.375</td></tr><tr><td>train/epoch_FN_6</td><td>8057.0249</td></tr><tr><td>train/epoch_FN_7</td><td>0.0</td></tr><tr><td>train/epoch_FN_8</td><td>0.0</td></tr><tr><td>train/epoch_FN_9</td><td>98732.92969</td></tr><tr><td>train/epoch_FP_0</td><td>18676.67578</td></tr><tr><td>train/epoch_FP_1</td><td>28053.20117</td></tr><tr><td>train/epoch_FP_10</td><td>21031.02539</td></tr><tr><td>train/epoch_FP_11</td><td>143.375</td></tr><tr><td>train/epoch_FP_12</td><td>33728.32422</td></tr><tr><td>train/epoch_FP_13</td><td>780.40002</td></tr><tr><td>train/epoch_FP_2</td><td>112354.82812</td></tr><tr><td>train/epoch_FP_3</td><td>0.0</td></tr><tr><td>train/epoch_FP_4</td><td>32766.05078</td></tr><tr><td>train/epoch_FP_5</td><td>34900.27734</td></tr><tr><td>train/epoch_FP_6</td><td>156.075</td></tr><tr><td>train/epoch_FP_7</td><td>78.475</td></tr><tr><td>train/epoch_FP_8</td><td>0.0</td></tr><tr><td>train/epoch_FP_9</td><td>0.0</td></tr><tr><td>train/epoch_IoU_0</td><td>0.67456</td></tr><tr><td>train/epoch_IoU_1</td><td>0.65998</td></tr><tr><td>train/epoch_IoU_10</td><td>0.58065</td></tr><tr><td>train/epoch_IoU_11</td><td>0.00196</td></tr><tr><td>train/epoch_IoU_12</td><td>0.56505</td></tr><tr><td>train/epoch_IoU_13</td><td>0.00716</td></tr><tr><td>train/epoch_IoU_2</td><td>0.0</td></tr><tr><td>train/epoch_IoU_3</td><td>0.0</td></tr><tr><td>train/epoch_IoU_4</td><td>0.22797</td></tr><tr><td>train/epoch_IoU_5</td><td>0.09992</td></tr><tr><td>train/epoch_IoU_6</td><td>2e-05</td></tr><tr><td>train/epoch_IoU_7</td><td>0.0</td></tr><tr><td>train/epoch_IoU_8</td><td>0.0</td></tr><tr><td>train/epoch_IoU_9</td><td>0.0</td></tr><tr><td>train/epoch_Precision_0</td><td>0.77107</td></tr><tr><td>train/epoch_Precision_1</td><td>0.74787</td></tr><tr><td>train/epoch_Precision_10</td><td>0.68706</td></tr><tr><td>train/epoch_Precision_11</td><td>0.07606</td></tr><tr><td>train/epoch_Precision_12</td><td>0.65685</td></tr><tr><td>train/epoch_Precision_13</td><td>0.13644</td></tr><tr><td>train/epoch_Precision_2</td><td>0.0</td></tr><tr><td>train/epoch_Precision_3</td><td>0.0</td></tr><tr><td>train/epoch_Precision_4</td><td>0.32624</td></tr><tr><td>train/epoch_Precision_5</td><td>0.11879</td></tr><tr><td>train/epoch_Precision_6</td><td>0.025</td></tr><tr><td>train/epoch_Precision_7</td><td>0.0</td></tr><tr><td>train/epoch_Precision_8</td><td>0.0</td></tr><tr><td>train/epoch_Precision_9</td><td>0.0</td></tr><tr><td>train/epoch_Recall_0</td><td>0.84361</td></tr><tr><td>train/epoch_Recall_1</td><td>0.84941</td></tr><tr><td>train/epoch_Recall_10</td><td>0.79839</td></tr><tr><td>train/epoch_Recall_11</td><td>0.00197</td></tr><tr><td>train/epoch_Recall_12</td><td>0.80651</td></tr><tr><td>train/epoch_Recall_13</td><td>0.00754</td></tr><tr><td>train/epoch_Recall_2</td><td>0.0</td></tr><tr><td>train/epoch_Recall_3</td><td>0.0</td></tr><tr><td>train/epoch_Recall_4</td><td>0.43978</td></tr><tr><td>train/epoch_Recall_5</td><td>0.40733</td></tr><tr><td>train/epoch_Recall_6</td><td>2e-05</td></tr><tr><td>train/epoch_Recall_7</td><td>0.0</td></tr><tr><td>train/epoch_Recall_8</td><td>0.0</td></tr><tr><td>train/epoch_Recall_9</td><td>0.0</td></tr><tr><td>train/epoch_TN_0</td><td>4096086.5</td></tr><tr><td>train/epoch_TN_1</td><td>4067517.75</td></tr><tr><td>train/epoch_TN_10</td><td>4106902.5</td></tr><tr><td>train/epoch_TN_11</td><td>4180989.75</td></tr><tr><td>train/epoch_TN_12</td><td>4079290.0</td></tr><tr><td>train/epoch_TN_13</td><td>4176076.5</td></tr><tr><td>train/epoch_TN_2</td><td>4081949.25</td></tr><tr><td>train/epoch_TN_3</td><td>4151317.25</td></tr><tr><td>train/epoch_TN_4</td><td>4124707.25</td></tr><tr><td>train/epoch_TN_5</td><td>4148546.0</td></tr><tr><td>train/epoch_TN_6</td><td>4186090.5</td></tr><tr><td>train/epoch_TN_7</td><td>4194225.75</td></tr><tr><td>train/epoch_TN_8</td><td>4194304.0</td></tr><tr><td>train/epoch_TN_9</td><td>4095571.25</td></tr><tr><td>train/epoch_TP_0</td><td>67167.10156</td></tr><tr><td>train/epoch_TP_1</td><td>83725.375</td></tr><tr><td>train/epoch_TP_10</td><td>53293.0</td></tr><tr><td>train/epoch_TP_11</td><td>32.325</td></tr><tr><td>train/epoch_TP_12</td><td>65320.94922</td></tr><tr><td>train/epoch_TP_13</td><td>157.175</td></tr><tr><td>train/epoch_TP_2</td><td>0.0</td></tr><tr><td>train/epoch_TP_3</td><td>0.0</td></tr><tr><td>train/epoch_TP_4</td><td>16272.0498</td></tr><tr><td>train/epoch_TP_5</td><td>4628.2749</td></tr><tr><td>train/epoch_TP_6</td><td>0.3</td></tr><tr><td>train/epoch_TP_7</td><td>0.0</td></tr><tr><td>train/epoch_TP_8</td><td>0.0</td></tr><tr><td>train/epoch_TP_9</td><td>0.0</td></tr><tr><td>train/epoch_loss</td><td>1.75049</td></tr><tr><td>train/epoch_loss_build</td><td>0.48449</td></tr><tr><td>train/epoch_loss_flood</td><td>0.48351</td></tr><tr><td>train/epoch_loss_road</td><td>0.48218</td></tr><tr><td>train/epoch_loss_speed</td><td>0.30031</td></tr><tr><td>train/iter_F1_0</td><td>0.83285</td></tr><tr><td>train/iter_F1_1</td><td>0.79593</td></tr><tr><td>train/iter_F1_10</td><td>0.71389</td></tr><tr><td>train/iter_F1_11</td><td>0.0</td></tr><tr><td>train/iter_F1_12</td><td>0.70187</td></tr><tr><td>train/iter_F1_13</td><td>0.0</td></tr><tr><td>train/iter_F1_2</td><td>0.0</td></tr><tr><td>train/iter_F1_3</td><td>0.0</td></tr><tr><td>train/iter_F1_4</td><td>0.39885</td></tr><tr><td>train/iter_F1_5</td><td>0.22842</td></tr><tr><td>train/iter_F1_6</td><td>0.0</td></tr><tr><td>train/iter_F1_7</td><td>0.0</td></tr><tr><td>train/iter_F1_8</td><td>0.0</td></tr><tr><td>train/iter_F1_9</td><td>0.0</td></tr><tr><td>train/iter_FN_0</td><td>18323.0</td></tr><tr><td>train/iter_FN_1</td><td>11604.0</td></tr><tr><td>train/iter_FN_10</td><td>18763.0</td></tr><tr><td>train/iter_FN_11</td><td>29525.0</td></tr><tr><td>train/iter_FN_12</td><td>9490.0</td></tr><tr><td>train/iter_FN_13</td><td>22900.0</td></tr><tr><td>train/iter_FN_2</td><td>0.0</td></tr><tr><td>train/iter_FN_3</td><td>30557.0</td></tr><tr><td>train/iter_FN_4</td><td>20955.0</td></tr><tr><td>train/iter_FN_5</td><td>4085.0</td></tr><tr><td>train/iter_FN_6</td><td>10634.0</td></tr><tr><td>train/iter_FN_7</td><td>0.0</td></tr><tr><td>train/iter_FN_8</td><td>0.0</td></tr><tr><td>train/iter_FN_9</td><td>91876.0</td></tr><tr><td>train/iter_FP_0</td><td>18458.0</td></tr><tr><td>train/iter_FP_1</td><td>29559.0</td></tr><tr><td>train/iter_FP_10</td><td>30667.0</td></tr><tr><td>train/iter_FP_11</td><td>2940.0</td></tr><tr><td>train/iter_FP_12</td><td>41044.0</td></tr><tr><td>train/iter_FP_13</td><td>3.0</td></tr><tr><td>train/iter_FP_2</td><td>112807.0</td></tr><tr><td>train/iter_FP_3</td><td>0.0</td></tr><tr><td>train/iter_FP_4</td><td>36021.0</td></tr><tr><td>train/iter_FP_5</td><td>41476.0</td></tr><tr><td>train/iter_FP_6</td><td>391.0</td></tr><tr><td>train/iter_FP_7</td><td>0.0</td></tr><tr><td>train/iter_FP_8</td><td>0.0</td></tr><tr><td>train/iter_FP_9</td><td>0.0</td></tr><tr><td>train/iter_IoU_0</td><td>0.71357</td></tr><tr><td>train/iter_IoU_1</td><td>0.66103</td></tr><tr><td>train/iter_IoU_10</td><td>0.55507</td></tr><tr><td>train/iter_IoU_11</td><td>0.0</td></tr><tr><td>train/iter_IoU_12</td><td>0.54068</td></tr><tr><td>train/iter_IoU_13</td><td>0.0</td></tr><tr><td>train/iter_IoU_2</td><td>0.0</td></tr><tr><td>train/iter_IoU_3</td><td>0.0</td></tr><tr><td>train/iter_IoU_4</td><td>0.2491</td></tr><tr><td>train/iter_IoU_5</td><td>0.12894</td></tr><tr><td>train/iter_IoU_6</td><td>0.0</td></tr><tr><td>train/iter_IoU_7</td><td>0.0</td></tr><tr><td>train/iter_IoU_8</td><td>0.0</td></tr><tr><td>train/iter_IoU_9</td><td>0.0</td></tr><tr><td>train/iter_Precision_0</td><td>0.83234</td></tr><tr><td>train/iter_Precision_1</td><td>0.73087</td></tr><tr><td>train/iter_Precision_10</td><td>0.66787</td></tr><tr><td>train/iter_Precision_11</td><td>0.0</td></tr><tr><td>train/iter_Precision_12</td><td>0.59172</td></tr><tr><td>train/iter_Precision_13</td><td>0.0</td></tr><tr><td>train/iter_Precision_2</td><td>0.0</td></tr><tr><td>train/iter_Precision_3</td><td>0.0</td></tr><tr><td>train/iter_Precision_4</td><td>0.34414</td></tr><tr><td>train/iter_Precision_5</td><td>0.13986</td></tr><tr><td>train/iter_Precision_6</td><td>0.0</td></tr><tr><td>train/iter_Precision_7</td><td>0.0</td></tr><tr><td>train/iter_Precision_8</td><td>0.0</td></tr><tr><td>train/iter_Precision_9</td><td>0.0</td></tr><tr><td>train/iter_Recall_0</td><td>0.83336</td></tr><tr><td>train/iter_Recall_1</td><td>0.8737</td></tr><tr><td>train/iter_Recall_10</td><td>0.76672</td></tr><tr><td>train/iter_Recall_11</td><td>0.0</td></tr><tr><td>train/iter_Recall_12</td><td>0.86242</td></tr><tr><td>train/iter_Recall_13</td><td>0.0</td></tr><tr><td>train/iter_Recall_2</td><td>0.0</td></tr><tr><td>train/iter_Recall_3</td><td>0.0</td></tr><tr><td>train/iter_Recall_4</td><td>0.47423</td></tr><tr><td>train/iter_Recall_5</td><td>0.62277</td></tr><tr><td>train/iter_Recall_6</td><td>0.0</td></tr><tr><td>train/iter_Recall_7</td><td>0.0</td></tr><tr><td>train/iter_Recall_8</td><td>0.0</td></tr><tr><td>train/iter_Recall_9</td><td>0.0</td></tr><tr><td>train/iter_TN_0</td><td>4065891.0</td></tr><tr><td>train/iter_TN_1</td><td>4072869.0</td></tr><tr><td>train/iter_TN_10</td><td>4083207.0</td></tr><tr><td>train/iter_TN_11</td><td>4161839.0</td></tr><tr><td>train/iter_TN_12</td><td>4084284.0</td></tr><tr><td>train/iter_TN_13</td><td>4171401.0</td></tr><tr><td>train/iter_TN_2</td><td>4081497.0</td></tr><tr><td>train/iter_TN_3</td><td>4163747.0</td></tr><tr><td>train/iter_TN_4</td><td>4118427.0</td></tr><tr><td>train/iter_TN_5</td><td>4141999.0</td></tr><tr><td>train/iter_TN_6</td><td>4183279.0</td></tr><tr><td>train/iter_TN_7</td><td>4194304.0</td></tr><tr><td>train/iter_TN_8</td><td>4194304.0</td></tr><tr><td>train/iter_TN_9</td><td>4102428.0</td></tr><tr><td>train/iter_TP_0</td><td>91632.0</td></tr><tr><td>train/iter_TP_1</td><td>80272.0</td></tr><tr><td>train/iter_TP_10</td><td>61667.0</td></tr><tr><td>train/iter_TP_11</td><td>0.0</td></tr><tr><td>train/iter_TP_12</td><td>59486.0</td></tr><tr><td>train/iter_TP_13</td><td>0.0</td></tr><tr><td>train/iter_TP_2</td><td>0.0</td></tr><tr><td>train/iter_TP_3</td><td>0.0</td></tr><tr><td>train/iter_TP_4</td><td>18901.0</td></tr><tr><td>train/iter_TP_5</td><td>6744.0</td></tr><tr><td>train/iter_TP_6</td><td>0.0</td></tr><tr><td>train/iter_TP_7</td><td>0.0</td></tr><tr><td>train/iter_TP_8</td><td>0.0</td></tr><tr><td>train/iter_TP_9</td><td>0.0</td></tr><tr><td>train/iter_loss</td><td>1.76884</td></tr><tr><td>train/iter_loss_build</td><td>0.4779</td></tr><tr><td>train/iter_loss_flood</td><td>0.49668</td></tr><tr><td>train/iter_loss_road</td><td>0.48281</td></tr><tr><td>train/iter_loss_speed</td><td>0.31145</td></tr><tr><td>train/mean_F1</td><td>0.25714</td></tr><tr><td>train/mean_IoU</td><td>0.20123</td></tr><tr><td>trainer/global_step</td><td>3999</td></tr><tr><td>val/epoch_F1_0</td><td>0.79112</td></tr><tr><td>val/epoch_F1_1</td><td>0.7121</td></tr><tr><td>val/epoch_F1_10</td><td>0.75453</td></tr><tr><td>val/epoch_F1_11</td><td>0.0</td></tr><tr><td>val/epoch_F1_12</td><td>0.68131</td></tr><tr><td>val/epoch_F1_13</td><td>0.0</td></tr><tr><td>val/epoch_F1_2</td><td>0.0</td></tr><tr><td>val/epoch_F1_3</td><td>0.0</td></tr><tr><td>val/epoch_F1_4</td><td>0.39817</td></tr><tr><td>val/epoch_F1_5</td><td>0.22592</td></tr><tr><td>val/epoch_F1_6</td><td>0.0</td></tr><tr><td>val/epoch_F1_7</td><td>0.0</td></tr><tr><td>val/epoch_F1_8</td><td>0.0</td></tr><tr><td>val/epoch_F1_9</td><td>0.0</td></tr><tr><td>val/epoch_FN_0</td><td>12779.09082</td></tr><tr><td>val/epoch_FN_1</td><td>21752.0</td></tr><tr><td>val/epoch_FN_10</td><td>13365.09082</td></tr><tr><td>val/epoch_FN_11</td><td>9681.63672</td></tr><tr><td>val/epoch_FN_12</td><td>23082.0918</td></tr><tr><td>val/epoch_FN_13</td><td>8156.18213</td></tr><tr><td>val/epoch_FN_2</td><td>0.0</td></tr><tr><td>val/epoch_FN_3</td><td>34000.63672</td></tr><tr><td>val/epoch_FN_4</td><td>20088.36328</td></tr><tr><td>val/epoch_FN_5</td><td>5092.36377</td></tr><tr><td>val/epoch_FN_6</td><td>4341.36377</td></tr><tr><td>val/epoch_FN_7</td><td>0.0</td></tr><tr><td>val/epoch_FN_8</td><td>0.0</td></tr><tr><td>val/epoch_FN_9</td><td>84881.1875</td></tr><tr><td>val/epoch_FP_0</td><td>20054.18164</td></tr><tr><td>val/epoch_FP_1</td><td>28267.18359</td></tr><tr><td>val/epoch_FP_10</td><td>19311.81836</td></tr><tr><td>val/epoch_FP_11</td><td>0.0</td></tr><tr><td>val/epoch_FP_12</td><td>26789.0</td></tr><tr><td>val/epoch_FP_13</td><td>0.0</td></tr><tr><td>val/epoch_FP_2</td><td>91946.1875</td></tr><tr><td>val/epoch_FP_3</td><td>0.0</td></tr><tr><td>val/epoch_FP_4</td><td>25831.91016</td></tr><tr><td>val/epoch_FP_5</td><td>28000.81836</td></tr><tr><td>val/epoch_FP_6</td><td>0.0</td></tr><tr><td>val/epoch_FP_7</td><td>0.0</td></tr><tr><td>val/epoch_FP_8</td><td>0.0</td></tr><tr><td>val/epoch_FP_9</td><td>0.0</td></tr><tr><td>val/epoch_IoU_0</td><td>0.65714</td></tr><tr><td>val/epoch_IoU_1</td><td>0.55551</td></tr><tr><td>val/epoch_IoU_10</td><td>0.61499</td></tr><tr><td>val/epoch_IoU_11</td><td>0.0</td></tr><tr><td>val/epoch_IoU_12</td><td>0.52082</td></tr><tr><td>val/epoch_IoU_13</td><td>0.0</td></tr><tr><td>val/epoch_IoU_2</td><td>0.0</td></tr><tr><td>val/epoch_IoU_3</td><td>0.0</td></tr><tr><td>val/epoch_IoU_4</td><td>0.25107</td></tr><tr><td>val/epoch_IoU_5</td><td>0.13186</td></tr><tr><td>val/epoch_IoU_6</td><td>0.0</td></tr><tr><td>val/epoch_IoU_7</td><td>0.0</td></tr><tr><td>val/epoch_IoU_8</td><td>0.0</td></tr><tr><td>val/epoch_IoU_9</td><td>0.0</td></tr><tr><td>val/epoch_Precision_0</td><td>0.75601</td></tr><tr><td>val/epoch_Precision_1</td><td>0.68708</td></tr><tr><td>val/epoch_Precision_10</td><td>0.73226</td></tr><tr><td>val/epoch_Precision_11</td><td>0.0</td></tr><tr><td>val/epoch_Precision_12</td><td>0.67353</td></tr><tr><td>val/epoch_Precision_13</td><td>0.0</td></tr><tr><td>val/epoch_Precision_2</td><td>0.0</td></tr><tr><td>val/epoch_Precision_3</td><td>0.0</td></tr><tr><td>val/epoch_Precision_4</td><td>0.38109</td></tr><tr><td>val/epoch_Precision_5</td><td>0.15539</td></tr><tr><td>val/epoch_Precision_6</td><td>0.0</td></tr><tr><td>val/epoch_Precision_7</td><td>0.0</td></tr><tr><td>val/epoch_Precision_8</td><td>0.0</td></tr><tr><td>val/epoch_Precision_9</td><td>0.0</td></tr><tr><td>val/epoch_Recall_0</td><td>0.83106</td></tr><tr><td>val/epoch_Recall_1</td><td>0.74118</td></tr><tr><td>val/epoch_Recall_10</td><td>0.78826</td></tr><tr><td>val/epoch_Recall_11</td><td>0.0</td></tr><tr><td>val/epoch_Recall_12</td><td>0.69444</td></tr><tr><td>val/epoch_Recall_13</td><td>0.0</td></tr><tr><td>val/epoch_Recall_2</td><td>0.0</td></tr><tr><td>val/epoch_Recall_3</td><td>0.0</td></tr><tr><td>val/epoch_Recall_4</td><td>0.42966</td></tr><tr><td>val/epoch_Recall_5</td><td>0.46121</td></tr><tr><td>val/epoch_Recall_6</td><td>0.0</td></tr><tr><td>val/epoch_Recall_7</td><td>0.0</td></tr><tr><td>val/epoch_Recall_8</td><td>0.0</td></tr><tr><td>val/epoch_Recall_9</td><td>0.0</td></tr><tr><td>val/epoch_TN_0</td><td>3742745.25</td></tr><tr><td>val/epoch_TN_1</td><td>3723686.75</td></tr><tr><td>val/epoch_TN_10</td><td>3753169.25</td></tr><tr><td>val/epoch_TN_11</td><td>3827153.25</td></tr><tr><td>val/epoch_TN_12</td><td>3733320.75</td></tr><tr><td>val/epoch_TN_13</td><td>3828678.75</td></tr><tr><td>val/epoch_TN_2</td><td>3744888.75</td></tr><tr><td>val/epoch_TN_3</td><td>3802834.25</td></tr><tr><td>val/epoch_TN_4</td><td>3775057.25</td></tr><tr><td>val/epoch_TN_5</td><td>3798241.25</td></tr><tr><td>val/epoch_TN_6</td><td>3832493.5</td></tr><tr><td>val/epoch_TN_7</td><td>3836835.0</td></tr><tr><td>val/epoch_TN_8</td><td>3836835.0</td></tr><tr><td>val/epoch_TN_9</td><td>3751954.0</td></tr><tr><td>val/epoch_TP_0</td><td>61256.63672</td></tr><tr><td>val/epoch_TP_1</td><td>63129.18359</td></tr><tr><td>val/epoch_TP_10</td><td>50989.0</td></tr><tr><td>val/epoch_TP_11</td><td>0.0</td></tr><tr><td>val/epoch_TP_12</td><td>53642.91016</td></tr><tr><td>val/epoch_TP_13</td><td>0.0</td></tr><tr><td>val/epoch_TP_2</td><td>0.0</td></tr><tr><td>val/epoch_TP_3</td><td>0.0</td></tr><tr><td>val/epoch_TP_4</td><td>15857.63672</td></tr><tr><td>val/epoch_TP_5</td><td>5500.81836</td></tr><tr><td>val/epoch_TP_6</td><td>0.0</td></tr><tr><td>val/epoch_TP_7</td><td>0.0</td></tr><tr><td>val/epoch_TP_8</td><td>0.0</td></tr><tr><td>val/epoch_TP_9</td><td>0.0</td></tr><tr><td>val/epoch_loss</td><td>1.67647</td></tr><tr><td>val/epoch_loss_build</td><td>0.48376</td></tr><tr><td>val/epoch_loss_flood</td><td>0.4283</td></tr><tr><td>val/epoch_loss_road</td><td>0.49134</td></tr><tr><td>val/epoch_loss_speed</td><td>0.27306</td></tr><tr><td>val/iter_F1_0</td><td>0.78359</td></tr><tr><td>val/iter_F1_1</td><td>0.71183</td></tr><tr><td>val/iter_F1_10</td><td>0.74284</td></tr><tr><td>val/iter_F1_11</td><td>0.0</td></tr><tr><td>val/iter_F1_12</td><td>0.67787</td></tr><tr><td>val/iter_F1_13</td><td>0.0</td></tr><tr><td>val/iter_F1_2</td><td>0.0</td></tr><tr><td>val/iter_F1_3</td><td>0.0</td></tr><tr><td>val/iter_F1_4</td><td>0.3946</td></tr><tr><td>val/iter_F1_5</td><td>0.24696</td></tr><tr><td>val/iter_F1_6</td><td>0.0</td></tr><tr><td>val/iter_F1_7</td><td>0.0</td></tr><tr><td>val/iter_F1_8</td><td>0.0</td></tr><tr><td>val/iter_F1_9</td><td>0.0</td></tr><tr><td>val/iter_FN_0</td><td>13875.40332</td></tr><tr><td>val/iter_FN_1</td><td>23602.2168</td></tr><tr><td>val/iter_FN_10</td><td>14471.74512</td></tr><tr><td>val/iter_FN_11</td><td>10583.65234</td></tr><tr><td>val/iter_FN_12</td><td>25013.65234</td></tr><tr><td>val/iter_FN_13</td><td>8916.07422</td></tr><tr><td>val/iter_FN_2</td><td>0.0</td></tr><tr><td>val/iter_FN_3</td><td>36794.60938</td></tr><tr><td>val/iter_FN_4</td><td>21790.85156</td></tr><tr><td>val/iter_FN_5</td><td>5566.80762</td></tr><tr><td>val/iter_FN_6</td><td>4745.83838</td></tr><tr><td>val/iter_FN_7</td><td>0.0</td></tr><tr><td>val/iter_FN_8</td><td>0.0</td></tr><tr><td>val/iter_FN_9</td><td>92135.42188</td></tr><tr><td>val/iter_FP_0</td><td>21744.44727</td></tr><tr><td>val/iter_FP_1</td><td>30696.26758</td></tr><tr><td>val/iter_FP_10</td><td>21008.57227</td></tr><tr><td>val/iter_FP_11</td><td>0.0</td></tr><tr><td>val/iter_FP_12</td><td>29162.44727</td></tr><tr><td>val/iter_FP_13</td><td>0.0</td></tr><tr><td>val/iter_FP_2</td><td>99825.76562</td></tr><tr><td>val/iter_FP_3</td><td>0.0</td></tr><tr><td>val/iter_FP_4</td><td>28120.9375</td></tr><tr><td>val/iter_FP_5</td><td>30389.24805</td></tr><tr><td>val/iter_FP_6</td><td>0.0</td></tr><tr><td>val/iter_FP_7</td><td>0.0</td></tr><tr><td>val/iter_FP_8</td><td>0.0</td></tr><tr><td>val/iter_FP_9</td><td>0.0</td></tr><tr><td>val/iter_IoU_0</td><td>0.64635</td></tr><tr><td>val/iter_IoU_1</td><td>0.55543</td></tr><tr><td>val/iter_IoU_10</td><td>0.5991</td></tr><tr><td>val/iter_IoU_11</td><td>0.0</td></tr><tr><td>val/iter_IoU_12</td><td>0.51715</td></tr><tr><td>val/iter_IoU_13</td><td>0.0</td></tr><tr><td>val/iter_IoU_2</td><td>0.0</td></tr><tr><td>val/iter_IoU_3</td><td>0.0</td></tr><tr><td>val/iter_IoU_4</td><td>0.24846</td></tr><tr><td>val/iter_IoU_5</td><td>0.14415</td></tr><tr><td>val/iter_IoU_6</td><td>0.0</td></tr><tr><td>val/iter_IoU_7</td><td>0.0</td></tr><tr><td>val/iter_IoU_8</td><td>0.0</td></tr><tr><td>val/iter_IoU_9</td><td>0.0</td></tr><tr><td>val/iter_Precision_0</td><td>0.74829</td></tr><tr><td>val/iter_Precision_1</td><td>0.68586</td></tr><tr><td>val/iter_Precision_10</td><td>0.71701</td></tr><tr><td>val/iter_Precision_11</td><td>0.0</td></tr><tr><td>val/iter_Precision_12</td><td>0.66358</td></tr><tr><td>val/iter_Precision_13</td><td>0.0</td></tr><tr><td>val/iter_Precision_2</td><td>0.0</td></tr><tr><td>val/iter_Precision_3</td><td>0.0</td></tr><tr><td>val/iter_Precision_4</td><td>0.37136</td></tr><tr><td>val/iter_Precision_5</td><td>0.16987</td></tr><tr><td>val/iter_Precision_6</td><td>0.0</td></tr><tr><td>val/iter_Precision_7</td><td>0.0</td></tr><tr><td>val/iter_Precision_8</td><td>0.0</td></tr><tr><td>val/iter_Precision_9</td><td>0.0</td></tr><tr><td>val/iter_Recall_0</td><td>0.82392</td></tr><tr><td>val/iter_Recall_1</td><td>0.7422</td></tr><tr><td>val/iter_Recall_10</td><td>0.78117</td></tr><tr><td>val/iter_Recall_11</td><td>0.0</td></tr><tr><td>val/iter_Recall_12</td><td>0.69716</td></tr><tr><td>val/iter_Recall_13</td><td>0.0</td></tr><tr><td>val/iter_Recall_2</td><td>0.0</td></tr><tr><td>val/iter_Recall_3</td><td>0.0</td></tr><tr><td>val/iter_Recall_4</td><td>0.43275</td></tr><tr><td>val/iter_Recall_5</td><td>0.50418</td></tr><tr><td>val/iter_Recall_6</td><td>0.0</td></tr><tr><td>val/iter_Recall_7</td><td>0.0</td></tr><tr><td>val/iter_Recall_8</td><td>0.0</td></tr><tr><td>val/iter_Recall_9</td><td>0.0</td></tr><tr><td>val/iter_TN_0</td><td>4068224.5</td></tr><tr><td>val/iter_TN_1</td><td>4047049.25</td></tr><tr><td>val/iter_TN_10</td><td>4079544.5</td></tr><tr><td>val/iter_TN_11</td><td>4159296.75</td></tr><tr><td>val/iter_TN_12</td><td>4057498.75</td></tr><tr><td>val/iter_TN_13</td><td>4160964.75</td></tr><tr><td>val/iter_TN_2</td><td>4070055.0</td></tr><tr><td>val/iter_TN_3</td><td>4133085.75</td></tr><tr><td>val/iter_TN_4</td><td>4102744.75</td></tr><tr><td>val/iter_TN_5</td><td>4127911.25</td></tr><tr><td>val/iter_TN_6</td><td>4165134.75</td></tr><tr><td>val/iter_TN_7</td><td>4169880.75</td></tr><tr><td>val/iter_TN_8</td><td>4169880.75</td></tr><tr><td>val/iter_TN_9</td><td>4077745.0</td></tr><tr><td>val/iter_TP_0</td><td>66036.57031</td></tr><tr><td>val/iter_TP_1</td><td>68533.20312</td></tr><tr><td>val/iter_TP_10</td><td>54856.57812</td></tr><tr><td>val/iter_TP_11</td><td>0.0</td></tr><tr><td>val/iter_TP_12</td><td>58205.69531</td></tr><tr><td>val/iter_TP_13</td><td>0.0</td></tr><tr><td>val/iter_TP_2</td><td>0.0</td></tr><tr><td>val/iter_TP_3</td><td>0.0</td></tr><tr><td>val/iter_TP_4</td><td>17224.0</td></tr><tr><td>val/iter_TP_5</td><td>6013.31689</td></tr><tr><td>val/iter_TP_6</td><td>0.0</td></tr><tr><td>val/iter_TP_7</td><td>0.0</td></tr><tr><td>val/iter_TP_8</td><td>0.0</td></tr><tr><td>val/iter_TP_9</td><td>0.0</td></tr><tr><td>val/iter_loss</td><td>1.70428</td></tr><tr><td>val/iter_loss_build</td><td>0.48592</td></tr><tr><td>val/iter_loss_flood</td><td>0.44584</td></tr><tr><td>val/iter_loss_road</td><td>0.49147</td></tr><tr><td>val/iter_loss_speed</td><td>0.28105</td></tr><tr><td>val/mean_F1</td><td>0.25451</td></tr><tr><td>val/mean_IoU</td><td>0.1951</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">3090_fold0</strong>: <a href=\"https://wandb.ai/syuchimu/SpaceNet8/runs/1lro960a\" target=\"_blank\">https://wandb.ai/syuchimu/SpaceNet8/runs/1lro960a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220724_010929-1lro960a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(cfg.folds):\n",
    "    print(f'#'*60)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*60)\n",
    "    \n",
    "    # Setting   \n",
    "    cfg.fold = fold\n",
    "    wandb_logger = WandbLogger(\n",
    "        config=cfg,\n",
    "        name=f\"{cfg.runname}_fold{fold}\",\n",
    "        project=f\"SpaceNet8\",\n",
    "        group=cfg.group,\n",
    "        tags=[f'fold{fold}', '3090', 'notebook',],\n",
    "        # entity='spaceshift',\n",
    "    )\n",
    "    \n",
    "    # Data\n",
    "    datamodule = SpaceNnet8Module(fold, cfg)\n",
    "    \n",
    "    # Model\n",
    "    model = SpaceNet8Model(cfg)\n",
    "    \n",
    "    # PATH\n",
    "    dirpath = f'{cfg.outdir}{cfg.group}/{cfg.runname}_fold-{fold}/'\n",
    "    filename = f\"best_fold-{fold}\"\n",
    "    best_model_path = dirpath + filename + \".ckpt\"\n",
    "\n",
    "\n",
    "    # Logging\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        dirpath=dirpath,\n",
    "        filename=filename,\n",
    "        monitor=\"val/mean_IoU\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "    )\n",
    "    wandb.save(cfg.notebook)\n",
    "    # logger = TensorBoardLogger()\n",
    "    \n",
    "    print(f'### Start Trainig')\n",
    "    # Train\n",
    "    trainer = Trainer(\n",
    "        logger=wandb_logger,\n",
    "        max_epochs=cfg.epoch,\n",
    "        callbacks=[lr_monitor, loss_checkpoint],\n",
    "        **cfg.trainer,\n",
    "    )\n",
    "    # 実行\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    # saving\n",
    "    with open(f'{dirpath}cfg.json', 'w') as f:\n",
    "        json.dump(cfg.to_dict(), f, indent=4)\n",
    "        \n",
    "    wandb.save(cfg.notebook)\n",
    "    wandb.finish()\n",
    "    break\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87596e26bd4d41899dde7caa03ad11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.107 MB of 0.107 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr-AdamW</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr-AdamW</td><td>0.001</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">3090_fold0</strong>: <a href=\"https://wandb.ai/syuchimu/SpaceNet8/runs/3u8mrbdx\" target=\"_blank\">https://wandb.ai/syuchimu/SpaceNet8/runs/3u8mrbdx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220723_234026-3u8mrbdx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f'[Error] {e} --> OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4c392ce440230bfb39e5200b05e64d7f0009bc2c4cd9541978c4d851b814910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
